"""
ÃœrÃ¼n Ä°zleme ve Analiz ModÃ¼lÃ¼ - Web Scraping
Selenium ve BeautifulSoup ile Trendyol Ã¼rÃ¼n verilerini Ã§eker
3 gÃ¼nlÃ¼k satÄ±ÅŸ verisi iÃ§in sepet iÅŸlemleri yapar
"""

import requests
from bs4 import BeautifulSoup
import time
import random
import logging
import threading
from typing import Dict, Optional, List
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import re
# Mevcut import'larÄ±n altÄ±na bu satÄ±rÄ± ekleyin:
from webdriver_manager.chrome import ChromeDriverManager

from product_tracking import (
    get_active_product_links, save_product_data, 
    get_product_statistics
)

# Scraping ayarlarÄ±
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

REQUEST_DELAY_MIN = 3  # Minimum bekleme sÃ¼resi (saniye)
REQUEST_DELAY_MAX = 7  # Maximum bekleme sÃ¼resi (saniye)
REQUEST_TIMEOUT = 20   # Ä°stek timeout sÃ¼resi (saniye)

# Global scraping durumu
scraping_status = {
    'is_running': False,
    'current_progress': 0,
    'total_items': 0,
    'current_item': '',
    'started_by': '',
    'start_time': None,
    'errors': [],
    'success_count': 0,
    'failed_count': 0
}

scraping_lock = threading.Lock()

def get_random_headers() -> Dict[str, str]:
    """Rastgele User-Agent ile header oluÅŸturur"""
    return {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
    }

def setup_chrome_driver() -> webdriver.Chrome:
    """Chrome WebDriver'Ä± headless modda kuruluma hazÄ±rlar"""
    print(f"ğŸ” PROD DEBUG: Chrome driver kuruluyor...")
    
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument(f'--user-agent={random.choice(USER_AGENTS)}')
    
    # VPS iÃ§in ayarlar
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    
    print(f"ğŸ” PROD DEBUG: Chrome options ayarlandÄ± (headless mode)")
    
    try:
        # Manuel path kullan
        service = Service('/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"âœ… PROD DEBUG: Chrome driver baÅŸarÄ±yla kuruldu")
        return driver
    except Exception as e:
        print(f"âŒ PROD DEBUG: Chrome driver kurulum hatasÄ±: {str(e)}")
        logging.error(f"PROD DEBUG: Chrome driver hatasÄ±: {str(e)}")
        raise

def scrape_product_basic_info(url: str) -> Optional[Dict[str, any]]:
    """
    BeautifulSoup ile temel Ã¼rÃ¼n bilgilerini Ã§eker (hÄ±zlÄ±)
    Returns: {'title': str, 'seller': str, 'price': float, 'rating': float, 'comments': int, 'questions': int, 'image_url': str}
    """
    try:
        headers = get_random_headers()
        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        
        # DEBUG: Sayfa iÃ§eriÄŸini kontrol et
        print(f"ğŸ” DEBUG: Sayfa baÅŸlÄ±ÄŸÄ±: {soup.title.string if soup.title else 'BaÅŸlÄ±k yok'}")
        print(f"ğŸ” DEBUG: Sayfa uzunluÄŸu: {len(response.text)} karakter")

        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # ÃœrÃ¼n baÅŸlÄ±ÄŸÄ±
        title_selectors = [
            'h1[data-testid="product-title"]',
            'h1.product-title',
            'h1.pr-new-br',
            'h1'
        ]
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['title'] = element.get_text(separator=' ', strip=True)
                break
        
# Fiyat - GÃœNCELLENDÄ°: Yeni campaign price format'Ä± eklendi
        price_selectors = [
           '.campaign-price-container.default',  # YENÄ°: Dolu container
           '.campaign-price-box',               # YENÄ°: Alternatif
           '.campaign-price',  # YENÄ°: Campaign price (en yÃ¼ksek Ã¶ncelik)
           '.prc-dsc', 
           'span.price-view-discounted',                    # "2.789,07 TL" - Ana selector
           '.price-view-price-view span.price-view-discounted',  # Daha spesifik
           '[data-testid="price"] .price-view-discounted',  # Data-testid ile
           '.campaign-price-content .new-price',            # YENÄ°: Campaign price format
           '.campaign-price-content p.new-price',           # YENÄ°: Daha spesifik selector
           '[data-testid="price-current-price"]',
           '.prc-slg', 
           '.product-price .prc-dsc',
        ]
        for selector in price_selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                print(f"ğŸ” DEBUG: Price element text ({selector}): '{price_text}'")
                
                # YENÄ° GELIÅMIÅ PRICE PARSING
                if price_text:
                    # Birden fazla satÄ±r varsa iÅŸle
                    lines = [line.strip() for line in price_text.split('\n') if line.strip()]
                    print(f"ğŸ” DEBUG: Price lines: {lines}")
                    
                    # TL iÃ§eren satÄ±rlarÄ± bul ve sadece fiyat formatÄ±ndakileri al
                    price_lines = []
                    for line in lines:
                        if 'TL' in line and any(char.isdigit() for char in line):
                            # "XXXX TL" formatÄ±nda mÄ± kontrol et (kampanya aÃ§Ä±klamasÄ± deÄŸil)
                            if re.search(r'^\d+[.,]?\d*\s*TL$', line.strip()) or 'indirim' not in line.lower():
                                price_lines.append(line)
                    
                    print(f"ğŸ” DEBUG: Valid TL price lines: {price_lines}")
                    
                    if price_lines:
                        # TÃ¼m geÃ§erli fiyatlarÄ± Ã§Ä±kar
                        valid_prices = []
                        for line in price_lines:
                            # Sadece rakam, nokta, virgÃ¼l bÄ±rak
                            price_clean = re.sub(r'[^\d,.]', '', line)
                            if price_clean:
                                try:
                                    # VirgÃ¼l ve nokta iÅŸleme
                                    if ',' in price_clean:
                                        if price_clean.count(',') == 1:
                                            test_price = float(price_clean.replace(',', '.'))
                                        else:
                                            parts = price_clean.split(',')
                                            if len(parts[-1]) == 2:
                                                integer_part = ''.join(parts[:-1])
                                                decimal_part = parts[-1]
                                                test_price = float(f"{integer_part}.{decimal_part}")
                                            else:
                                                test_price = float(price_clean.replace(',', ''))
                                    else:
                                        test_price = float(price_clean)
                                    
                                    # Makul fiyat aralÄ±ÄŸÄ±nda mÄ±?
                                    if 10 <= test_price <= 1000000:
                                        valid_prices.append(test_price)
                                        
                                except ValueError:
                                    continue
                        
                        if valid_prices:
                            # EN KÃœÃ‡ÃœK FÄ°YATI AL (indirimli fiyat)
                            result['price'] = min(valid_prices)
                            print(f"ğŸ” DEBUG: Multiple prices found, selected minimum: {result['price']} from {valid_prices}")
                            break
                    else:
                        # Tek satÄ±r ise eski yÃ¶ntemi kullan
                        price_clean = re.sub(r'[^\d,]', '', price_text)
                        if price_clean:
                            try:
                                if ',' in price_clean:
                                    if price_clean.count(',') == 1:
                                        result['price'] = float(price_clean.replace(',', '.'))
                                    else:
                                        parts = price_clean.split(',')
                                        if len(parts[-1]) == 2:
                                            integer_part = ''.join(parts[:-1])
                                            decimal_part = parts[-1]
                                            result['price'] = float(f"{integer_part}.{decimal_part}")
                                        else:
                                            result['price'] = float(price_clean.replace(',', ''))
                                else:
                                    result['price'] = float(price_clean)
                                
                                print(f"ğŸ” DEBUG: Single price found ({selector}): {result['price']}")
                                break
                            except ValueError:
                                print(f"ğŸ” DEBUG: Price parse hatasÄ± ({selector}): {price_clean}")
                                continue
        
        # SatÄ±cÄ± adÄ±
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]'
        ]
        for selector in seller_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['seller'] = element.get_text(strip=True)
                break
        
        # Puan
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-line-count',
            '.stars-container .rating',
            '[data-testid="product-rating"]'
        ]
        for selector in rating_selectors:
            element = soup.select_one(selector)
            if element:
                rating_text = element.get_text(strip=True)
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    try:
                        result['rating'] = float(rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        # Yorum sayÄ±sÄ±  
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.rating-line-count',
            '.comments-summary .rating-line-count',
            '[data-testid="reviews-count"]',
            'a[data-testid="questions-summary-link"] span'
        ]
        for selector in comment_selectors:
            element = soup.select_one(selector)
            if element:
                comment_text = element.get_text(strip=True)
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    break
        
        # Soru sayÄ±sÄ±
        question_selectors = [
            'a[data-testid="questions-summary-link"] span:last-child',
            '.qa-section-header',
            '.questions-answers .header',
            '[data-testid="questions-count"]'
        ]
        for selector in question_selectors:
            element = soup.select_one(selector)
            if element:
                question_text = element.get_text(strip=True)
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    break
        
        # ÃœrÃ¼n resmi
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]'
        ]
        for selector in image_selectors:
            element = soup.select_one(selector)
            if element and element.get('src'):
                result['image_url'] = element.get('src')
                break
        
        # SatÄ±cÄ± puanÄ± (varsa)
        seller_rating_selectors = [
            '.score-badge',
            '._body_03c70b5',
            '.merchant-rating',
            '.seller-score',
            '[data-testid="seller-rating"]'
        ]
        for selector in seller_rating_selectors:
            element = soup.select_one(selector)
            if element:
                seller_rating_text = element.get_text(strip=True)
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        return result
        
    except requests.exceptions.RequestException as e:
        logging.error(f"Request hatasÄ± - {url}: {str(e)}")
        return None
    except Exception as e:
        logging.error(f"Scraping hatasÄ± - {url}: {str(e)}")
        return None


def scrape_product_with_selenium(url: str) -> Optional[Dict[str, any]]:
    """
    Selenium ile JavaScript yÃ¼klÃ¼ sayfadan veri Ã§eker
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        print(f"ğŸ” SELENIUM DEBUG: Sayfaya gidiliyor: {url}")
        driver.get(url)
        
        # Sayfa yÃ¼klenene kadar bekle
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScript'in tam yÃ¼klenmesi iÃ§in bekleme
        time.sleep(5)
        
        # SayfayÄ± aÅŸaÄŸÄ± kaydÄ±r (lazy loading iÃ§in)
        driver.execute_script("window.scrollTo(0, 1000);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # Title Ã§ek (her zaman Ã§alÄ±ÅŸÄ±yor)
        try:
            title_selectors = ['h1', '[data-testid="product-title"]', '.product-title']
            for selector in title_selectors:
                try:
                    title_element = driver.find_element(By.CSS_SELECTOR, selector)
                    result['title'] = title_element.text.strip()
                    print(f"ğŸ” SELENIUM DEBUG: Title bulundu ({selector}): {result['title'][:50]}...")
                    break
                except:
                    continue
        except Exception as e:
            print(f"ğŸ” SELENIUM DEBUG: Title hatasÄ±: {str(e)}")
        
        # Rating Ã§ek - Ã‡oklu selector deneme
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-score',
            '.product-rating-score',
            '[data-testid="product-rating"]',
            '.stars-container .rating',
            '.review-rating',
            'span[class*="rating"]',
            'div[class*="rating"]'
        ]
        
        for selector in rating_selectors:
            try:
                rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                rating_text = rating_element.text.strip()
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    result['rating'] = float(rating_match.group(1).replace(',', '.'))
                    print(f"ğŸ” SELENIUM DEBUG: Rating bulundu ({selector}): {result['rating']}")
                    break
            except:
                continue
        
        if not result['rating']:
            print("ğŸ” SELENIUM DEBUG: Rating bulunamadÄ± - tÃ¼m selector'lar denendi")
        
        # Comment count Ã§ek - Ã‡oklu selector deneme
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.review-count',
            '.comments-count',
            '[data-testid="reviews-count"]',
            '.rating-line-count',
            'a[href*="yorum"] span',
            'span[class*="review"]',
            'div[class*="review"] span'
        ]
        
        for selector in comment_selectors:
            try:
                comment_element = driver.find_element(By.CSS_SELECTOR, selector)
                comment_text = comment_element.text.strip()
                print(f"ğŸ” SELENIUM DEBUG: Comment element text ({selector}): '{comment_text}'")
                
                # SayÄ± Ã§Ä±karma
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    print(f"ğŸ” SELENIUM DEBUG: Comment count bulundu ({selector}): {result['comments']}")
                    break
            except:
                continue
        
        if not result['comments']:
            print("ğŸ” SELENIUM DEBUG: Comment count bulunamadÄ± - tÃ¼m selector'lar denendi")
        
        # Question count Ã§ek
        question_selectors = [
            'a[data-testid="questions-summary-link"] span',
            '.questions-summary-questions-summary span',
            'a[class*="questions-summary"] span',
            'a[href*="saticiya-sor"] span',
            'a[data-testid="questions-summary-link"] span:last-child',
            '.questions-summary-questions-summary span b',
            'a[data-testid="questions-summary-link"] b',
            'a[data-testid="questions-summary-link"] span:last-child',
            '.questions-count',
            '.qa-count',
            '[data-testid="questions-count"]',
            'a[href*="soru"] span'
        ]

        for selector in question_selectors:
            try:
                question_element = driver.find_element(By.CSS_SELECTOR, selector)
                question_text = question_element.text.strip()
                print(f"ğŸ” SELENIUM DEBUG: Question element text ({selector}): '{question_text}'")
                
                # SayÄ± Ã§Ä±karma - "202 Soru-Cevap" formatÄ±ndan
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    print(f"ğŸ” SELENIUM DEBUG: Question count bulundu ({selector}): {result['questions']}")
                    break
            except:
                continue
        
        # Price Ã§ek - FULL DEBUG MODE
        price_selectors = [
            '.campaign-price-container.default',  # YENÄ°: Dolu container
            '.campaign-price-box',               # YENÄ°: Alternatif
            '.campaign-price',  # YENÄ°: Campaign price (en yÃ¼ksek Ã¶ncelik)
            '.prc-dsc',                                      # âœ… Ä°NDÄ°RÄ°MLÄ° FÄ°YAT
            'span.price-view-discounted',                    
            '.price-view-price-view span.price-view-discounted',  
            '[data-testid="price"] .price-view-discounted',  
            '.campaign-price-content .new-price',            
            '.campaign-price-content p.new-price',           
            'div.campaign-price-content p.new-price',        
            '[data-testid="price-current-price"]',
            '.price-current',
            '.prc-slg', 
            '.product-price .prc-dsc',
            '.prc-cntr .prc-dsc',
            '.price-container span',
            '.product-price span:last-child',
            'span[data-testid*="price"]',
        ]

        print(f"ğŸ” SELENIUM DEBUG: Price Ã§ekme baÅŸlÄ±yor...")

        # Ã–NCE SAYFADA HANGÄ° PRICE ELEMENT'LERÄ° VAR BAKALIM
        try:
            print(f"ğŸ” SELENIUM DEBUG: Sayfadaki tÃ¼m price-related elementler:")
            
            # Genel price element'lerini bul
            all_price_elements = driver.find_elements(By.CSS_SELECTOR, '*[class*="price"], *[class*="prc"], *[data-testid*="price"]')
            for i, elem in enumerate(all_price_elements[:10]):  # Ä°lk 10 tanesi
                try:
                    elem_class = elem.get_attribute('class')
                    elem_text = elem.text.strip()
                    elem_tag = elem.tag_name
                    print(f"ğŸ” SELENIUM DEBUG: Element {i+1}: <{elem_tag} class='{elem_class}'>{elem_text}</tag>")
                except:
                    pass
                    
            print(f"ğŸ” SELENIUM DEBUG: Toplam price-related element sayÄ±sÄ±: {len(all_price_elements)}")
            
        except Exception as e:
            print(f"ğŸ” SELENIUM DEBUG: Price element listesi hatasÄ±: {str(e)}")

        # ÅÄ°MDÄ° SELECTOR'LARI TEK TEK DENE
        for selector in price_selectors:
            try:
                price_element = driver.find_element(By.CSS_SELECTOR, selector)
                price_text = price_element.text.strip()
                print(f"ğŸ” SELENIUM DEBUG: Price element BULUNDU ({selector}): '{price_text}'")
                
                # YENÄ° ADVANCED PRICE PARSING
                if price_text:
                    # Birden fazla satÄ±r varsa en son satÄ±rdaki fiyatÄ± al
                    lines = [line.strip() for line in price_text.split('\n') if line.strip()]
                    print(f"ğŸ” SELENIUM DEBUG: Price lines: {lines}")
                    
                    # TL iÃ§eren satÄ±rlarÄ± bul ve sadece fiyat formatÄ±ndakileri al
                    price_lines = []
                    for line in lines:
                        if 'TL' in line and any(char.isdigit() for char in line):
                            # "XXXX TL" formatÄ±nda mÄ± kontrol et (kampanya aÃ§Ä±klamasÄ± deÄŸil)
                            if re.search(r'^\d+[.,]?\d*\s*TL$', line.strip()) or 'indirim' not in line.lower():
                                price_lines.append(line)
                    
                    print(f"ğŸ” SELENIUM DEBUG: Valid TL price lines: {price_lines}")
                    
                    if price_lines:
                        # TÃ¼m geÃ§erli fiyatlarÄ± Ã§Ä±kar
                        valid_prices = []
                        for line in price_lines:
                            # SadÄ± rakam, nokta, virgÃ¼l ve TL'yi koru
                            clean_text = re.sub(r'[^\d.,TL\s]', '', line)
                            print(f"ğŸ” SELENIUM DEBUG: After regex clean: '{clean_text}'")
                            
                            # TL'yi kaldÄ±r ve sadece sayÄ±larÄ± al
                            clean_text = clean_text.replace('TL', '').strip()
                            
                            # SayÄ±larÄ± bul
                            numbers = re.findall(r'\d+[.,]?\d*', clean_text)
                            print(f"ğŸ” SELENIUM DEBUG: Found numbers in line: {numbers}")
                            
                            for num_str in numbers:
                                try:
                                    # VirgÃ¼lÃ¼ noktaya Ã§evir
                                    num_str = num_str.replace(',', '.')
                                    price = float(num_str)
                                    # Makul fiyat aralÄ±ÄŸÄ±nda mÄ±?
                                    if 10 <= price <= 1000000:
                                        valid_prices.append(price)
                                except ValueError:
                                    continue
                        
                        if valid_prices:
                            # EN KÃœÃ‡ÃœK FÄ°YATI AL (indirimli fiyat)
                            result['price'] = min(valid_prices)
                            print(f"ğŸ” SELENIUM DEBUG: Multiple prices found, selected minimum: {result['price']} from {valid_prices}")
                            break
                    else:
                        print(f"ğŸ” SELENIUM DEBUG: Valid TL price lines bulunamadÄ±")
                else:
                    print(f"ğŸ” SELENIUM DEBUG: Price element boÅŸ ({selector})")
                    
            except Exception as e:
                print(f"ğŸ” SELENIUM DEBUG: Price selector hatasÄ± ({selector}): {str(e)}")
                continue
        
        # Seller name Ã§ek
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]',
            '.seller-name'
        ]
        
        for selector in seller_selectors:
            try:
                seller_element = driver.find_element(By.CSS_SELECTOR, selector)
                result['seller'] = seller_element.text.strip()
                print(f"ğŸ” SELENIUM DEBUG: Seller bulundu ({selector}): {result['seller']}")
                break
            except:
                continue
        
        # Seller rating Ã§ek
        seller_rating_selectors = [
            '.score-badge',
            '._body_03c70b5',
            'div[class*="_body_03c70b5"]',
            'div.score-badge',
            '[class*="score-badge"]',
            'div[style*="background-color: rgb(4, 155, 36)"]',
            'div[style*="background-color: rgb"]',
            '.merchant-rating',
            '.seller-score',
            '[data-testid="seller-rating"]',
            'span[class*="rating"]',
            'div[class*="rating"]'
        ]

        for selector in seller_rating_selectors:
            try:
                seller_rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                seller_rating_text = seller_rating_element.text.strip()
                print(f"ğŸ” SELENIUM DEBUG: Seller rating element text ({selector}): '{seller_rating_text}'")
                
                # SayÄ± Ã§Ä±karma - "9.4" formatÄ±ndan
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        print(f"ğŸ” SELENIUM DEBUG: Seller rating bulundu ({selector}): {result['seller_rating']}")
                        break
                    except ValueError:
                        continue
            except Exception as e:
                print(f"ğŸ” SELENIUM DEBUG: Seller rating hatasÄ± ({selector}): {str(e)}")
                continue

        if not result['seller_rating']:
            print("ğŸ” SELENIUM DEBUG: Seller rating bulunamadÄ± - tÃ¼m selector'lar denendi")
        
        # Image URL Ã§ek
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]',
            '.product-image img'
        ]

        print(f"ğŸ” PROD DEBUG: Image selector aramasÄ± baÅŸlÄ±yor...")
        logging.info(f"PROD DEBUG: Image URL Ã§ekme baÅŸlÄ±yor - URL: {url}")

        for i, selector in enumerate(image_selectors):
            try:
                print(f"ğŸ” PROD DEBUG: Image selector {i+1}/{len(image_selectors)} deneniyor: {selector}")
                image_element = driver.find_element(By.CSS_SELECTOR, selector)
                image_url = image_element.get_attribute('src')
                print(f"ğŸ” PROD DEBUG: Element bulundu! Src attribute: {image_url}")
                
                if image_url:
                    result['image_url'] = image_url
                    print(f"âœ… PROD DEBUG: Image URL baÅŸarÄ±yla Ã§ekildi ({selector}): {image_url[:100]}...")
                    logging.info(f"PROD DEBUG: Image URL baÅŸarÄ±yla elde edildi: {image_url}")
                    break
                else:
                    print(f"âš ï¸ PROD DEBUG: Element bulundu ama src attribute boÅŸ ({selector})")
            except Exception as selector_error:
                print(f"âŒ PROD DEBUG: Image selector hatasÄ± ({selector}): {str(selector_error)}")
                continue

        if not result.get('image_url'):
            print(f"âŒ PROD DEBUG: HiÃ§bir image selector Ã§alÄ±ÅŸmadÄ±! TÃ¼m selector'lar denendi.")
            logging.warning(f"PROD DEBUG: Image URL bulunamadÄ± - URL: {url}")
        
        # Sales data Ã§ek (sepet iÅŸlemi)
        if not result.get('sales_3day'):
            try:
                print(f"ğŸ” SELENIUM DEBUG: Sales data Ã§ekiliyor...")
                sales_data = scrape_cart_sales_data(url)
                if sales_data:
                    result['sales_3day'] = sales_data
                    result['daily_estimated_sales'] = sales_data / 3.0
                    print(f"ğŸ” SELENIUM DEBUG: Sales data eklendi: {sales_data}")
                else:
                    print(f"ğŸ” SELENIUM DEBUG: Sales data bulunamadÄ±")
            except Exception as e:
                print(f"ğŸ” SELENIUM DEBUG: Sales data hatasÄ±: {str(e)}")
        
        print(f"ğŸ” SELENIUM DEBUG: Final result: {result}")
        return result
        
    except Exception as e:
        print(f"ğŸ” SELENIUM DEBUG: Genel hata: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_cart_sales_data(url: str, max_retries: int = 2) -> Optional[int]:
    """
    Selenium ile sepete ekleme iÅŸlemi yaparak 3 gÃ¼nlÃ¼k satÄ±ÅŸ verisini Ã§eker
    Returns: sales_3day (int) or None
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        for attempt in range(max_retries):
            try:
                logging.info(f"Sepet verisi Ã§ekiliyor (deneme {attempt + 1}): {url}")
                
                # Ã–nce sepeti temizle
                try:
                    print(f"ğŸ” SELENIUM DEBUG: Sepet temizleniyor...")
                    cart_url = "https://www.trendyol.com/sepet"
                    driver.get(cart_url)
                    time.sleep(2)
                    
                    # Sepetteki Ã¼rÃ¼nleri sil
                    delete_buttons = driver.find_elements(By.CSS_SELECTOR, '.remove-item, .delete-item, [class*="remove"], [class*="delete"]')
                    for btn in delete_buttons:
                        try:
                            driver.execute_script("arguments[0].click();", btn)
                            time.sleep(0.5)
                        except:
                            continue
                    
                    print(f"ğŸ” SELENIUM DEBUG: Sepet temizlendi")
                except Exception as e:
                    print(f"ğŸ” SELENIUM DEBUG: Sepet temizleme hatasÄ±: {str(e)}")
                
                # ÃœrÃ¼n sayfasÄ±na git
                driver.get(url)
                
                # Sayfa yÃ¼klenene kadar bekle
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                time.sleep(random.uniform(2, 4))

                # SayfayÄ± scroll et (sepete ekle butonu gÃ¶rÃ¼nÃ¼r olsun)
                driver.execute_script("window.scrollTo(0, 800);")
                time.sleep(2)
                driver.execute_script("window.scrollTo(0, 400);")
                time.sleep(1)

                print(f"ğŸ” SELENIUM DEBUG: Sayfa scroll edildi, buton aranÄ±yor...")

                # Sepete ekle butonunu bul ve tÄ±kla
                cart_button = None
                
                # Ana buton selector'Ä±
                main_selector = 'button[data-testid="add-to-cart-button"]'
                
                try:
                    # Butonun var olmasÄ±nÄ± bekle
                    print(f"ğŸ” SELENIUM DEBUG: Sepete ekle butonu aranÄ±yor...")
                    cart_button = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                    )
                    print(f"ğŸ” SELENIUM DEBUG: Buton bulundu: {main_selector}")
                    
                    # Loading'in bitmesini bekle
                    try:
                        WebDriverWait(driver, 5).until_not(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                        )
                        print(f"ğŸ” SELENIUM DEBUG: Loading bitti")
                    except:
                        print(f"ğŸ” SELENIUM DEBUG: Loading timeout - devam ediliyor")
                    
                    # Butonun durumunu kontrol et
                    time.sleep(1)
                    button_text = cart_button.text.strip()
                    print(f"ğŸ” SELENIUM DEBUG: Buton text: '{button_text}'")
                    
                    # EÄŸer "Sepete Eklendi" ise yenile ve bekle
                    if "Eklendi" in button_text:
                        print(f"ğŸ” SELENIUM DEBUG: Buton eklendi durumunda - sayfa yenileniyor...")
                        driver.refresh()
                        time.sleep(3)
                        
                        # Yeniden buton ara
                        cart_button = WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                        )
                        
                        # Loading bekle
                        try:
                            WebDriverWait(driver, 5).until_not(
                                EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                            )
                        except:
                            pass
                        
                        time.sleep(1)
                        button_text = cart_button.text.strip()
                        print(f"ğŸ” SELENIUM DEBUG: Yenileme sonrasÄ± buton text: '{button_text}'")
                    
                    # Buton durumunu final kontrol
                    if cart_button and cart_button.is_enabled() and "Eklendi" not in button_text:
                        print(f"ğŸ” SELENIUM DEBUG: Sepete ekle butonu hazÄ±r!")
                    else:
                        print(f"ğŸ” SELENIUM DEBUG: Buton hala kullanÄ±lamaz durumda")
                        cart_button = None
                        
                except Exception as e:
                    print(f"ğŸ” SELENIUM DEBUG: Buton bulma hatasÄ±: {str(e)}")
                    cart_button = None

                # Buton bulunamazsa dÃ¶ngÃ¼yÃ¼ devam ettir
                if not cart_button:
                    logging.warning(f"Sepete ekle butonu bulunamadÄ± veya zaten eklendi: {url}")
                    continue
                
                # Sepete ekle
                driver.execute_script("arguments[0].click();", cart_button)
                print(f"ğŸ” SELENIUM DEBUG: Sepete ekleme butonu tÄ±klandÄ±")
                time.sleep(random.uniform(2, 3))
                
                # Sepet sayfasÄ±na git
                cart_url = "https://www.trendyol.com/sepet"
                driver.get(cart_url)
                print(f"ğŸ” SELENIUM DEBUG: Sepet sayfasÄ±na gidildi")
                
                # Sepet yÃ¼klenene kadar bekle - satÄ±ÅŸ verisi odaklÄ±
                cart_loaded = False
                cart_wait_selectors = [
                    ".order-count-text",  # Direkt satÄ±ÅŸ verisi
                    ".social-proof-label",  # SatÄ±ÅŸ container'Ä±
                    "[class*='social-proof']",
                    ".cart-item",
                    ".basket-item", 
                    "[class*='cart']",
                    "body"  # fallback
                ]
                
                for selector in cart_wait_selectors:
                    try:
                        element = WebDriverWait(driver, 3).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                        )
                        print(f"ğŸ” SELENIUM DEBUG: Sepet yÃ¼klendi ({selector}): {element.text[:50] if element.text else 'boÅŸ'}")
                        cart_loaded = True
                        break
                    except:
                        print(f"ğŸ” SELENIUM DEBUG: Sepet selector bulunamadÄ±: {selector}")
                        continue
                
                if not cart_loaded:
                    print(f"ğŸ” SELENIUM DEBUG: Sepet yÃ¼klenemedi, devam ediliyor...")
                
                time.sleep(2)  # Extra wait
                
                time.sleep(random.uniform(1, 2))
                
                # 3 gÃ¼nlÃ¼k satÄ±ÅŸ verisini ara
                sales_selectors = [
                    '.order-count-text',  # YENÄ°: "24 tanesi satÄ±ldÄ±" iÃ§in
                    'p[class*="order-count"]',  # YENÄ°
                    '.social-proof-label p',  # YENÄ°
                    'div[class*="social-proof"] p',  # YENÄ°
                    '*[class*="order-count-text"]',  # YENÄ°
                    '.sales-count',
                    '.last-sold',
                    '[data-testid="sales-info"]',
                    '*[class*="sold"]',
                    '*[class*="sales"]'
                ]
                
                sales_3day = None
                page_source = driver.page_source
                
                # Sayfada satÄ±ÅŸ pattern'lerini ara
                sales_patterns = [
                    r'(\d+)\s*tanesi\s*satÄ±ldÄ±',  # YENÄ°: "24 tanesi satÄ±ldÄ±"
                    r'(\d+)\s*adet\s*satÄ±ldÄ±',   # YENÄ°: "24 adet satÄ±ldÄ±"
                    r'(\d+)\s*adet.*?3.*?gÃ¼n',
                    r'3.*?gÃ¼n.*?(\d+)\s*adet',
                    r'Son.*?3.*?gÃ¼n.*?(\d+)',
                    r'(\d+).*?satÄ±ldÄ±.*?3.*?gÃ¼n'
                ]
                
                print(f"ğŸ” SELENIUM DEBUG: Sepet sayfasÄ±nda satÄ±ÅŸ verisi aranÄ±yor...")
                
                # Debug: Sayfa source'unu kontrol et
                page_source = driver.page_source
                if "tanesi satÄ±ldÄ±" in page_source:
                    print(f"ğŸ” SELENIUM DEBUG: 'tanesi satÄ±ldÄ±' metni sayfada var!")
                elif "adet satÄ±ldÄ±" in page_source:
                    print(f"ğŸ” SELENIUM DEBUG: 'adet satÄ±ldÄ±' metni sayfada var!")
                elif "satÄ±ldÄ±" in page_source:
                    print(f"ğŸ” SELENIUM DEBUG: 'satÄ±ldÄ±' metni sayfada var!")
                else:
                    print(f"ğŸ” SELENIUM DEBUG: SatÄ±ÅŸ metni bulunamadÄ±, sayfa iÃ§eriÄŸi:")
                    print(f"ğŸ” SELENIUM DEBUG: Ä°lk 1000 karakter: {page_source[:1000]}")
                
                for pattern in sales_patterns:
                    match = re.search(pattern, page_source, re.IGNORECASE | re.DOTALL)
                    if match:
                        try:
                            sales_3day = int(match.group(1))
                            print(f"ğŸ” SELENIUM DEBUG: Pattern ile satÄ±ÅŸ bulundu ({pattern}): {sales_3day}")
                            break
                        except (ValueError, IndexError):
                            continue
                
                # EÄŸer pattern match yapmadÄ±ysa, DOM elementlerini kontrol et
                if sales_3day is None:
                    print(f"ğŸ” SELENIUM DEBUG: Pattern bulunamadÄ±, DOM elementleri kontrol ediliyor...")
                    for selector in sales_selectors:
                        try:
                            elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            for element in elements:
                                text = element.text.strip()
                                print(f"ğŸ” SELENIUM DEBUG: Element text ({selector}): '{text}'")
                                
                                # "tanesi satÄ±ldÄ±" veya "adet satÄ±ldÄ±" ara
                                if 'tanesi satÄ±ldÄ±' in text or 'adet satÄ±ldÄ±' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"ğŸ” SELENIUM DEBUG: DOM'dan satÄ±ÅŸ bulundu ({selector}): {sales_3day}")
                                        break
                                # Eski format: "3 gÃ¼n" ara
                                elif '3' in text and 'gÃ¼n' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"ğŸ” SELENIUM DEBUG: DOM'dan 3 gÃ¼nlÃ¼k satÄ±ÅŸ bulundu ({selector}): {sales_3day}")
                                        break
                            if sales_3day:
                                break
                        except Exception as e:
                            print(f"ğŸ” SELENIUM DEBUG: DOM element hatasÄ± ({selector}): {str(e)}")
                            continue
                
                if sales_3day is not None:
                    print(f"ğŸ” SELENIUM DEBUG: BaÅŸarÄ±lÄ±! SatÄ±ÅŸ verisi: {sales_3day}")
                    return sales_3day
                else:
                    print(f"ğŸ” SELENIUM DEBUG: SatÄ±ÅŸ verisi bulunamadÄ±")
                    logging.warning(f"3 gÃ¼nlÃ¼k satÄ±ÅŸ verisi bulunamadÄ±: {url}")
                    
            except TimeoutException:
                logging.warning(f"Timeout - sepet verisi alÄ±namadÄ± (deneme {attempt + 1}): {url}")
                continue
            except Exception as e:
                logging.error(f"Sepet verisi hatasÄ± (deneme {attempt + 1}) - {url}: {str(e)}")
                continue
        
        return None
        
    except Exception as e:
        logging.error(f"Selenium sepet verisi hatasÄ± - {url}: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_single_product(product_link_id: int, product_url: str, scraped_by: str) -> bool:
    """
    Tek bir Ã¼rÃ¼n iÃ§in complete scraping yapar
    """
    try:
        print(f"ğŸ” DEBUG: ÃœrÃ¼n scraping baÅŸlatÄ±lÄ±yor: {product_url}")
        
        # Selenium ile veri Ã§ek
        basic_info = scrape_product_with_selenium(product_url)
        if not basic_info:
            print(f"ğŸ” DEBUG: Selenium veri Ã§ekme baÅŸarÄ±sÄ±z: {product_url}")
            return False
        
        print(f"ğŸ” DEBUG: Kaydedilecek veri: {basic_info}")
        
        # Veri kaydet - SALES ALANLARI EKLENDÄ°
        print(f"ğŸ” PROD DEBUG: save_product_data Ã§aÄŸrÄ±lÄ±yor...")
        print(f"ğŸ” PROD DEBUG: product_link_id: {product_link_id}")
        print(f"ğŸ” PROD DEBUG: product_image_url: {basic_info.get('image_url', 'None')}")
        logging.info(f"PROD DEBUG: Veri kaydediliyor - Link ID: {product_link_id}, Image URL var mÄ±: {bool(basic_info.get('image_url'))}")


        success = save_product_data(
            product_link_id=product_link_id,
            seller_name=basic_info.get('seller', 'Bilinmiyor'),
            product_title=basic_info.get('title', ''),
            price=basic_info.get('price', 0.0),
            comment_count=basic_info.get('comments', 0),
            question_count=basic_info.get('questions', 0), 
            rating=basic_info.get('rating', 0.0),
            sales_3day=basic_info.get('sales_3day'),  # âœ… Bu yeterli
            seller_rating=basic_info.get('seller_rating', 0.0),
            scraped_by=scraped_by,
            product_image_url=basic_info.get('image_url')
            # daily_estimated_sales KALDIRDIK - zaten fonksiyonda hesaplanÄ±yor!
        )
        
        # Debug Ã§Ä±ktÄ±larÄ± SONRA ekle
        if success:
            print(f"âœ… PROD DEBUG: save_product_data baÅŸarÄ±lÄ± - Image URL kaydedildi mi: {bool(basic_info.get('image_url'))}")
            logging.info(f"PROD DEBUG: Veri kaydetme baÅŸarÄ±lÄ± - Link ID: {product_link_id}")
            print(f"ğŸ” DEBUG: ÃœrÃ¼n scraping baÅŸarÄ±lÄ±: {product_url}")
            return True
        else:
            print(f"âŒ PROD DEBUG: save_product_data baÅŸarÄ±sÄ±z!")
            logging.error(f"PROD DEBUG: Veri kaydetme baÅŸarÄ±sÄ±z - Link ID: {product_link_id}")
            print(f"ğŸ” DEBUG: Veri kaydetme hatasÄ±: {product_url}")
            return False
            
    except Exception as e:
        print(f"ğŸ” DEBUG: ÃœrÃ¼n scraping exception: {product_url} - {str(e)}")
        return False

def update_scraping_status(is_running: bool = None, progress: int = None, 
                          total: int = None, current_item: str = None,
                          started_by: str = None, error: str = None,
                          success_count: int = None, failed_count: int = None):
    """Scraping durumunu gÃ¼nceller"""
    global scraping_status
    
    with scraping_lock:
        if is_running is not None:
            scraping_status['is_running'] = is_running
            if is_running:
                scraping_status['start_time'] = time.time()
                scraping_status['errors'] = []
                scraping_status['success_count'] = 0
                scraping_status['failed_count'] = 0
            
        if progress is not None:
            scraping_status['current_progress'] = progress
            
        if total is not None:
            scraping_status['total_items'] = total
            
        if current_item is not None:
            scraping_status['current_item'] = current_item
            
        if started_by is not None:
            scraping_status['started_by'] = started_by
            
        if error is not None:
            scraping_status['errors'].append(error)
            
        if success_count is not None:
            scraping_status['success_count'] = success_count
            
        if failed_count is not None:
            scraping_status['failed_count'] = failed_count

def get_scraping_status() -> Dict:
    """Mevcut scraping durumunu dÃ¶ndÃ¼rÃ¼r"""
    with scraping_lock:
        status = scraping_status.copy()
        if status['start_time']:
            status['elapsed_time'] = time.time() - status['start_time']
        else:
            status['elapsed_time'] = 0
        return status

def start_single_product_scraping(product_link_id: int, product_url: str, scraped_by: str):
    """
    Tek Ã¼rÃ¼n iÃ§in arka planda scraping baÅŸlatÄ±r (yeni Ã¼rÃ¼n eklendiÄŸinde)
    """
    def scrape_worker():
        try:
            success = scrape_single_product(product_link_id, product_url, scraped_by)
            if success:
                logging.info(f"Tek Ã¼rÃ¼n scraping tamamlandÄ±: {product_url}")
            else:
                logging.error(f"Tek Ã¼rÃ¼n scraping baÅŸarÄ±sÄ±z: {product_url}")
        except Exception as e:
            logging.error(f"Tek Ã¼rÃ¼n scraping worker hatasÄ±: {str(e)}")
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_manual_update(username: str) -> bool:
    """
    Manuel gÃ¼ncelleme baÅŸlatÄ±r (Admin yetkisi gerekli)
    TÃ¼m aktif Ã¼rÃ¼nler iÃ§in scraping yapar
    """
    def manual_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # TÃ¼m aktif Ã¼rÃ¼nleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Manuel gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_products} Ã¼rÃ¼n")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu gÃ¼ncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"ÃœrÃ¼n {i+1}/{total_products}: {product_url[:50]}..."
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Scraping hatasÄ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Bekleme sÃ¼resi
                time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
            
            logging.info(f"Manuel gÃ¼ncelleme tamamlandÄ±: {success_count}/{total_products} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            error_msg = f"Manuel gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, yeni iÅŸlem baÅŸlatÄ±lmadÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=manual_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def start_scheduled_update(username: str = "scheduler") -> bool:
    """
    ZamanlanmÄ±ÅŸ gÃ¼ncelleme baÅŸlatÄ±r
    """
    def scheduled_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # TÃ¼m aktif Ã¼rÃ¼nleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Otomatik gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_products} Ã¼rÃ¼n")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu gÃ¼ncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"Otomatik: ÃœrÃ¼n {i+1}/{total_products}"
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Otomatik scraping hatasÄ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Otomatik gÃ¼ncellemede daha uzun bekleme
                time.sleep(random.uniform(REQUEST_DELAY_MIN + 2, REQUEST_DELAY_MAX + 3))
            
            logging.info(f"Otomatik gÃ¼ncelleme tamamlandÄ±: {success_count}/{total_products} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            error_msg = f"Otomatik gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, otomatik iÅŸlem atlandÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scheduled_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def is_scraping_running() -> bool:
    """Scraping iÅŸleminin devam edip etmediÄŸini kontrol eder"""
    return scraping_status['is_running']

def get_scraping_statistics() -> Dict:
    """
    Scraping istatistiklerini getirir
    """
    try:
        product_stats = get_product_statistics()
        scraping_stats = get_scraping_status()
        
        return {
            'product_stats': product_stats,
            'scraping_status': scraping_stats
        }
        
    except Exception as e:
        logging.error(f"Scraping istatistik hatasÄ±: {str(e)}")
        return {}

# Test fonksiyonu
def test_single_scraping(url: str):
    """Tek bir URL iÃ§in test scraping"""
    logging.info(f"Test scraping baÅŸlatÄ±lÄ±yor: {url}")
    
    basic_info = scrape_product_basic_info(url)
    print("Temel bilgiler:", basic_info)
    
    sales_data = scrape_cart_sales_data(url)
    print("3 gÃ¼nlÃ¼k satÄ±ÅŸ:", sales_data)
    
    return basic_info, sales_data