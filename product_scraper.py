"""
√úr√ºn ƒ∞zleme ve Analiz Mod√ºl√º - Web Scraping
Selenium ve BeautifulSoup ile Trendyol √ºr√ºn verilerini √ßeker
3 g√ºnl√ºk satƒ±≈ü verisi i√ßin sepet i≈ülemleri yapar
"""

import requests
from bs4 import BeautifulSoup
import time
import random
import logging
import threading
from typing import Dict, Optional, List
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import re
# Mevcut import'larƒ±n altƒ±na bu satƒ±rƒ± ekleyin:
from webdriver_manager.chrome import ChromeDriverManager

from product_tracking import (
    get_active_product_links, save_product_data, 
    get_product_statistics
)

# Scraping ayarlarƒ±
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

REQUEST_DELAY_MIN = 3  # Minimum bekleme s√ºresi (saniye)
REQUEST_DELAY_MAX = 7  # Maximum bekleme s√ºresi (saniye)
REQUEST_TIMEOUT = 20   # ƒ∞stek timeout s√ºresi (saniye)

# Global scraping durumu
scraping_status = {
    'is_running': False,
    'current_progress': 0,
    'total_items': 0,
    'current_item': '',
    'started_by': '',
    'start_time': None,
    'errors': [],
    'success_count': 0,
    'failed_count': 0
}

scraping_lock = threading.Lock()

def get_random_headers() -> Dict[str, str]:
    """Rastgele User-Agent ile header olu≈üturur"""
    return {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
    }

def setup_chrome_driver() -> webdriver.Chrome:
    """Chrome WebDriver'ƒ± headless modda kuruluma hazƒ±rlar"""
    print(f"üîç PROD DEBUG: Chrome driver kuruluyor...")
    
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument(f'--user-agent={random.choice(USER_AGENTS)}')
    
    # VPS i√ßin ayarlar
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    
    print(f"üîç PROD DEBUG: Chrome options ayarlandƒ± (headless mode)")
    
    try:
        # Manuel path kullan
        service = Service('/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"‚úÖ PROD DEBUG: Chrome driver ba≈üarƒ±yla kuruldu")
        return driver
    except Exception as e:
        print(f"‚ùå PROD DEBUG: Chrome driver kurulum hatasƒ±: {str(e)}")
        logging.error(f"PROD DEBUG: Chrome driver hatasƒ±: {str(e)}")
        raise

def scrape_product_basic_info(url: str) -> Optional[Dict[str, any]]:
    """
    BeautifulSoup ile temel √ºr√ºn bilgilerini √ßeker (hƒ±zlƒ±)
    Returns: {'title': str, 'seller': str, 'price': float, 'rating': float, 'comments': int, 'questions': int, 'image_url': str}
    """
    try:
        headers = get_random_headers()
        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        
        # DEBUG: Sayfa i√ßeriƒüini kontrol et
        print(f"üîç DEBUG: Sayfa ba≈ülƒ±ƒüƒ±: {soup.title.string if soup.title else 'Ba≈ülƒ±k yok'}")
        print(f"üîç DEBUG: Sayfa uzunluƒüu: {len(response.text)} karakter")

        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # √úr√ºn ba≈ülƒ±ƒüƒ±
        title_selectors = [
            'h1[data-testid="product-title"]',
            'h1.product-title',
            'h1.pr-new-br',
            'h1'
        ]
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['title'] = element.get_text(separator=' ', strip=True)
                break
        
        # Fiyat - G√úNCELLENDƒ∞: Yeni campaign price format'ƒ± eklendi
        price_selectors = [
           '.prc-dsc', 
           'span.price-view-discounted',                    # "2.789,07 TL" - Ana selector
           '.price-view-price-view span.price-view-discounted',  # Daha spesifik
           '[data-testid="price"] .price-view-discounted',  # Data-testid ile
           '.campaign-price-content .new-price',            # YENƒ∞: Campaign price format
           '.campaign-price-content p.new-price',           # YENƒ∞: Daha spesifik selector
           '[data-testid="price-current-price"]',
           '.prc-slg', 
           '.product-price .prc-dsc',
        ]
        for selector in price_selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                print(f"üîç DEBUG: Price element text ({selector}): '{price_text}'")
                
                # Fiyat temizleme - TL, ‚Ç∫ sembollerini kaldƒ±r ve noktalarƒ± temizle
                price_clean = re.sub(r'[^\d,]', '', price_text)  # Sadece rakam ve virg√ºl√º bƒ±rak
                if price_clean:
                    try:
                        # Binlik ayƒ±rƒ±cƒ± noktalarƒ± kaldƒ±r, virg√ºl√º nokta yap
                        if ',' in price_clean:
                            # Eƒüer virg√ºl varsa, en son virg√ºl√º decimal ayƒ±rƒ±cƒ± olarak kabul et
                            if price_clean.count(',') == 1:
                                result['price'] = float(price_clean.replace(',', '.'))
                            else:
                                # Birden fazla virg√ºl varsa, sonuncusu hari√ß hepsini binlik ayƒ±rƒ±cƒ± kabul et
                                parts = price_clean.split(',')
                                if len(parts[-1]) == 2:  # Son kƒ±sƒ±m 2 haneliyse decimal
                                    integer_part = ''.join(parts[:-1])
                                    decimal_part = parts[-1]
                                    result['price'] = float(f"{integer_part}.{decimal_part}")
                                else:  # Decimal deƒüilse t√ºm virg√ºlleri kaldƒ±r
                                    result['price'] = float(price_clean.replace(',', ''))
                        else:
                            result['price'] = float(price_clean)
                        
                        print(f"üîç DEBUG: Price bulundu ({selector}): {result['price']}")
                        break
                    except ValueError:
                        print(f"üîç DEBUG: Price parse hatasƒ± ({selector}): {price_clean}")
                        continue
        
        # Satƒ±cƒ± adƒ±
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]'
        ]
        for selector in seller_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['seller'] = element.get_text(strip=True)
                break
        
        # Puan
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-line-count',
            '.stars-container .rating',
            '[data-testid="product-rating"]'
        ]
        for selector in rating_selectors:
            element = soup.select_one(selector)
            if element:
                rating_text = element.get_text(strip=True)
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    try:
                        result['rating'] = float(rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        # Yorum sayƒ±sƒ±  
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.rating-line-count',
            '.comments-summary .rating-line-count',
            '[data-testid="reviews-count"]',
            'a[data-testid="questions-summary-link"] span'
        ]
        for selector in comment_selectors:
            element = soup.select_one(selector)
            if element:
                comment_text = element.get_text(strip=True)
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    break
        
        # Soru sayƒ±sƒ±
        question_selectors = [
            'a[data-testid="questions-summary-link"] span:last-child',
            '.qa-section-header',
            '.questions-answers .header',
            '[data-testid="questions-count"]'
        ]
        for selector in question_selectors:
            element = soup.select_one(selector)
            if element:
                question_text = element.get_text(strip=True)
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    break
        
        # √úr√ºn resmi
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]'
        ]
        for selector in image_selectors:
            element = soup.select_one(selector)
            if element and element.get('src'):
                result['image_url'] = element.get('src')
                break
        
        # Satƒ±cƒ± puanƒ± (varsa)
        seller_rating_selectors = [
            '.score-badge',
            '._body_03c70b5',
            '.merchant-rating',
            '.seller-score',
            '[data-testid="seller-rating"]'
        ]
        for selector in seller_rating_selectors:
            element = soup.select_one(selector)
            if element:
                seller_rating_text = element.get_text(strip=True)
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        return result
        
    except requests.exceptions.RequestException as e:
        logging.error(f"Request hatasƒ± - {url}: {str(e)}")
        return None
    except Exception as e:
        logging.error(f"Scraping hatasƒ± - {url}: {str(e)}")
        return None


def scrape_product_with_selenium(url: str) -> Optional[Dict[str, any]]:
    """
    Selenium ile JavaScript y√ºkl√º sayfadan veri √ßeker
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        print(f"üîç SELENIUM DEBUG: Sayfaya gidiliyor: {url}")
        driver.get(url)
        
        # Sayfa y√ºklenene kadar bekle
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScript'in tam y√ºklenmesi i√ßin bekleme
        time.sleep(5)
        
        # Sayfayƒ± a≈üaƒüƒ± kaydƒ±r (lazy loading i√ßin)
        driver.execute_script("window.scrollTo(0, 1000);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # Title √ßek (her zaman √ßalƒ±≈üƒ±yor)
        try:
            title_selectors = ['h1', '[data-testid="product-title"]', '.product-title']
            for selector in title_selectors:
                try:
                    title_element = driver.find_element(By.CSS_SELECTOR, selector)
                    result['title'] = title_element.text.strip()
                    print(f"üîç SELENIUM DEBUG: Title bulundu ({selector}): {result['title'][:50]}...")
                    break
                except:
                    continue
        except Exception as e:
            print(f"üîç SELENIUM DEBUG: Title hatasƒ±: {str(e)}")
        
        # Rating √ßek - √áoklu selector deneme
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-score',
            '.product-rating-score',
            '[data-testid="product-rating"]',
            '.stars-container .rating',
            '.review-rating',
            'span[class*="rating"]',
            'div[class*="rating"]'
        ]
        
        for selector in rating_selectors:
            try:
                rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                rating_text = rating_element.text.strip()
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    result['rating'] = float(rating_match.group(1).replace(',', '.'))
                    print(f"üîç SELENIUM DEBUG: Rating bulundu ({selector}): {result['rating']}")
                    break
            except:
                continue
        
        if not result['rating']:
            print("üîç SELENIUM DEBUG: Rating bulunamadƒ± - t√ºm selector'lar denendi")
        
        # Comment count √ßek - √áoklu selector deneme
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.review-count',
            '.comments-count',
            '[data-testid="reviews-count"]',
            '.rating-line-count',
            'a[href*="yorum"] span',
            'span[class*="review"]',
            'div[class*="review"] span'
        ]
        
        for selector in comment_selectors:
            try:
                comment_element = driver.find_element(By.CSS_SELECTOR, selector)
                comment_text = comment_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Comment element text ({selector}): '{comment_text}'")
                
                # Sayƒ± √ßƒ±karma
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    print(f"üîç SELENIUM DEBUG: Comment count bulundu ({selector}): {result['comments']}")
                    break
            except:
                continue
        
        if not result['comments']:
            print("üîç SELENIUM DEBUG: Comment count bulunamadƒ± - t√ºm selector'lar denendi")
        
        # Question count √ßek
        question_selectors = [
            'a[data-testid="questions-summary-link"] span',
            '.questions-summary-questions-summary span',
            'a[class*="questions-summary"] span',
            'a[href*="saticiya-sor"] span',
            'a[data-testid="questions-summary-link"] span:last-child',
            '.questions-summary-questions-summary span b',
            'a[data-testid="questions-summary-link"] b',
            'a[data-testid="questions-summary-link"] span:last-child',
            '.questions-count',
            '.qa-count',
            '[data-testid="questions-count"]',
            'a[href*="soru"] span'
        ]

        for selector in question_selectors:
            try:
                question_element = driver.find_element(By.CSS_SELECTOR, selector)
                question_text = question_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Question element text ({selector}): '{question_text}'")
                
                # Sayƒ± √ßƒ±karma - "202 Soru-Cevap" formatƒ±ndan
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    print(f"üîç SELENIUM DEBUG: Question count bulundu ({selector}): {result['questions']}")
                    break
            except:
                continue
        
        # Price √ßek - G√úNCELLENDƒ∞: Yeni campaign price format'ƒ± eklendi
        price_selectors = [
            '.prc-dsc',                                      # ‚úÖ ƒ∞NDƒ∞Rƒ∞MLƒ∞ Fƒ∞YAT
            'span.price-view-discounted',                    
            '.price-view-price-view span.price-view-discounted',  
            '[data-testid="price"] .price-view-discounted',  
            '.campaign-price-content .new-price',            
            '.campaign-price-content p.new-price',           
            'div.campaign-price-content p.new-price',        
            '[data-testid="price-current-price"]',
            '.price-current',
            '.prc-slg', 
            '.product-price .prc-dsc',
            '.prc-cntr .prc-dsc',
            '.price-container span',
            '.product-price span:last-child',
            'span[data-testid*="price"]',
            # ‚ùå BUNLARI EN SONA TA≈ûIYIN:
            'span[class*="price"]',        # ‚Üê ESKƒ∞ Fƒ∞YAT ALIYOR
            'div[class*="price"] span',    # ‚Üê ESKƒ∞ Fƒ∞YAT ALIYOR
        ]

        for selector in price_selectors:
            try:
                price_element = driver.find_element(By.CSS_SELECTOR, selector)
                price_text = price_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Price element text ({selector}): '{price_text}'")
                
                # Fiyat temizleme - TL, ‚Ç∫ sembollerini kaldƒ±r ve geli≈ümi≈ü parsing
                if price_text:
                    # "2.959 TL" formatƒ±nƒ± handle et
                    price_clean = re.sub(r'[^\d,.]', '', price_text)  # Sadece rakam, virg√ºl ve nokta bƒ±rak
                    
                    if price_clean:
                        try:
                            # Binlik ayƒ±rƒ±cƒ± ve decimal ayƒ±rƒ±cƒ± mantƒ±ƒüƒ±
                            if '.' in price_clean and ',' in price_clean:
                                # Hem nokta hem virg√ºl varsa, hangisi sonuncu onu decimal kabul et
                                last_dot = price_clean.rfind('.')
                                last_comma = price_clean.rfind(',')
                                
                                if last_dot > last_comma:
                                    # Nokta decimal ayƒ±rƒ±cƒ±, virg√ºl binlik
                                    price_clean = price_clean.replace(',', '')
                                    result['price'] = float(price_clean)
                                else:
                                    # Virg√ºl decimal ayƒ±rƒ±cƒ±, nokta binlik
                                    price_clean = price_clean.replace('.', '').replace(',', '.')
                                    result['price'] = float(price_clean)
                            elif '.' in price_clean:
                                # Sadece nokta var
                                parts = price_clean.split('.')
                                if len(parts) > 1 and len(parts[-1]) <= 2:
                                    # Son kƒ±sƒ±m 2 hane veya daha azsa decimal
                                    result['price'] = float(price_clean)
                                else:
                                    # Binlik ayƒ±rƒ±cƒ± olarak kullanƒ±lmƒ±≈ü
                                    result['price'] = float(price_clean.replace('.', ''))
                            elif ',' in price_clean:
                                # Sadece virg√ºl var
                                parts = price_clean.split(',')
                                if len(parts) == 2 and len(parts[-1]) <= 2:
                                    # Decimal ayƒ±rƒ±cƒ±
                                    result['price'] = float(price_clean.replace(',', '.'))
                                else:
                                    # Binlik ayƒ±rƒ±cƒ±
                                    result['price'] = float(price_clean.replace(',', ''))
                            else:
                                # Sadece rakam var
                                result['price'] = float(price_clean)
                            
                            print(f"üîç SELENIUM DEBUG: Price bulundu ({selector}): {result['price']}")
                            break
                            
                        except ValueError as ve:
                            print(f"üîç SELENIUM DEBUG: Price parse hatasƒ± ({selector}): {price_clean} - {ve}")
                            continue
                            
            except Exception as e:
                print(f"üîç SELENIUM DEBUG: Price hatasƒ± ({selector}): {str(e)}")
                continue
        
        # Seller name √ßek
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]',
            '.seller-name'
        ]
        
        for selector in seller_selectors:
            try:
                seller_element = driver.find_element(By.CSS_SELECTOR, selector)
                result['seller'] = seller_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Seller bulundu ({selector}): {result['seller']}")
                break
            except:
                continue
        
        # Seller rating √ßek
        seller_rating_selectors = [
            '.score-badge',
            '._body_03c70b5',
            'div[class*="_body_03c70b5"]',
            'div.score-badge',
            '[class*="score-badge"]',
            'div[style*="background-color: rgb(4, 155, 36)"]',
            'div[style*="background-color: rgb"]',
            '.merchant-rating',
            '.seller-score',
            '[data-testid="seller-rating"]',
            'span[class*="rating"]',
            'div[class*="rating"]'
        ]

        for selector in seller_rating_selectors:
            try:
                seller_rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                seller_rating_text = seller_rating_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Seller rating element text ({selector}): '{seller_rating_text}'")
                
                # Sayƒ± √ßƒ±karma - "9.4" formatƒ±ndan
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        print(f"üîç SELENIUM DEBUG: Seller rating bulundu ({selector}): {result['seller_rating']}")
                        break
                    except ValueError:
                        continue
            except Exception as e:
                print(f"üîç SELENIUM DEBUG: Seller rating hatasƒ± ({selector}): {str(e)}")
                continue

        if not result['seller_rating']:
            print("üîç SELENIUM DEBUG: Seller rating bulunamadƒ± - t√ºm selector'lar denendi")
        
        # Image URL √ßek
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]',
            '.product-image img'
        ]

        print(f"üîç PROD DEBUG: Image selector aramasƒ± ba≈ülƒ±yor...")
        logging.info(f"PROD DEBUG: Image URL √ßekme ba≈ülƒ±yor - URL: {url}")

        for i, selector in enumerate(image_selectors):
            try:
                print(f"üîç PROD DEBUG: Image selector {i+1}/{len(image_selectors)} deneniyor: {selector}")
                image_element = driver.find_element(By.CSS_SELECTOR, selector)
                image_url = image_element.get_attribute('src')
                print(f"üîç PROD DEBUG: Element bulundu! Src attribute: {image_url}")
                
                if image_url:
                    result['image_url'] = image_url
                    print(f"‚úÖ PROD DEBUG: Image URL ba≈üarƒ±yla √ßekildi ({selector}): {image_url[:100]}...")
                    logging.info(f"PROD DEBUG: Image URL ba≈üarƒ±yla elde edildi: {image_url}")
                    break
                else:
                    print(f"‚ö†Ô∏è PROD DEBUG: Element bulundu ama src attribute bo≈ü ({selector})")
            except Exception as selector_error:
                print(f"‚ùå PROD DEBUG: Image selector hatasƒ± ({selector}): {str(selector_error)}")
                continue

        if not result.get('image_url'):
            print(f"‚ùå PROD DEBUG: Hi√ßbir image selector √ßalƒ±≈ümadƒ±! T√ºm selector'lar denendi.")
            logging.warning(f"PROD DEBUG: Image URL bulunamadƒ± - URL: {url}")
        
        # Sales data √ßek (sepet i≈ülemi)
        if not result.get('sales_3day'):
            try:
                print(f"üîç SELENIUM DEBUG: Sales data √ßekiliyor...")
                sales_data = scrape_cart_sales_data(url)
                if sales_data:
                    result['sales_3day'] = sales_data
                    result['daily_estimated_sales'] = sales_data / 3.0
                    print(f"üîç SELENIUM DEBUG: Sales data eklendi: {sales_data}")
                else:
                    print(f"üîç SELENIUM DEBUG: Sales data bulunamadƒ±")
            except Exception as e:
                print(f"üîç SELENIUM DEBUG: Sales data hatasƒ±: {str(e)}")
        
        print(f"üîç SELENIUM DEBUG: Final result: {result}")
        return result
        
    except Exception as e:
        print(f"üîç SELENIUM DEBUG: Genel hata: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_cart_sales_data(url: str, max_retries: int = 2) -> Optional[int]:
    """
    Selenium ile sepete ekleme i≈ülemi yaparak 3 g√ºnl√ºk satƒ±≈ü verisini √ßeker
    Returns: sales_3day (int) or None
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        for attempt in range(max_retries):
            try:
                logging.info(f"Sepet verisi √ßekiliyor (deneme {attempt + 1}): {url}")
                
                # √ñnce sepeti temizle
                try:
                    print(f"üîç SELENIUM DEBUG: Sepet temizleniyor...")
                    cart_url = "https://www.trendyol.com/sepet"
                    driver.get(cart_url)
                    time.sleep(2)
                    
                    # Sepetteki √ºr√ºnleri sil
                    delete_buttons = driver.find_elements(By.CSS_SELECTOR, '.remove-item, .delete-item, [class*="remove"], [class*="delete"]')
                    for btn in delete_buttons:
                        try:
                            driver.execute_script("arguments[0].click();", btn)
                            time.sleep(0.5)
                        except:
                            continue
                    
                    print(f"üîç SELENIUM DEBUG: Sepet temizlendi")
                except Exception as e:
                    print(f"üîç SELENIUM DEBUG: Sepet temizleme hatasƒ±: {str(e)}")
                
                # √úr√ºn sayfasƒ±na git
                driver.get(url)
                
                # Sayfa y√ºklenene kadar bekle
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                time.sleep(random.uniform(2, 4))

                # Sayfayƒ± scroll et (sepete ekle butonu g√∂r√ºn√ºr olsun)
                driver.execute_script("window.scrollTo(0, 800);")
                time.sleep(2)
                driver.execute_script("window.scrollTo(0, 400);")
                time.sleep(1)

                print(f"üîç SELENIUM DEBUG: Sayfa scroll edildi, buton aranƒ±yor...")

                # Sepete ekle butonunu bul ve tƒ±kla
                cart_button = None
                
                # Ana buton selector'ƒ±
                main_selector = 'button[data-testid="add-to-cart-button"]'
                
                try:
                    # Butonun var olmasƒ±nƒ± bekle
                    print(f"üîç SELENIUM DEBUG: Sepete ekle butonu aranƒ±yor...")
                    cart_button = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                    )
                    print(f"üîç SELENIUM DEBUG: Buton bulundu: {main_selector}")
                    
                    # Loading'in bitmesini bekle
                    try:
                        WebDriverWait(driver, 5).until_not(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                        )
                        print(f"üîç SELENIUM DEBUG: Loading bitti")
                    except:
                        print(f"üîç SELENIUM DEBUG: Loading timeout - devam ediliyor")
                    
                    # Butonun durumunu kontrol et
                    time.sleep(1)
                    button_text = cart_button.text.strip()
                    print(f"üîç SELENIUM DEBUG: Buton text: '{button_text}'")
                    
                    # Eƒüer "Sepete Eklendi" ise yenile ve bekle
                    if "Eklendi" in button_text:
                        print(f"üîç SELENIUM DEBUG: Buton eklendi durumunda - sayfa yenileniyor...")
                        driver.refresh()
                        time.sleep(3)
                        
                        # Yeniden buton ara
                        cart_button = WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                        )
                        
                        # Loading bekle
                        try:
                            WebDriverWait(driver, 5).until_not(
                                EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                            )
                        except:
                            pass
                        
                        time.sleep(1)
                        button_text = cart_button.text.strip()
                        print(f"üîç SELENIUM DEBUG: Yenileme sonrasƒ± buton text: '{button_text}'")
                    
                    # Buton durumunu final kontrol
                    if cart_button and cart_button.is_enabled() and "Eklendi" not in button_text:
                        print(f"üîç SELENIUM DEBUG: Sepete ekle butonu hazƒ±r!")
                    else:
                        print(f"üîç SELENIUM DEBUG: Buton hala kullanƒ±lamaz durumda")
                        cart_button = None
                        
                except Exception as e:
                    print(f"üîç SELENIUM DEBUG: Buton bulma hatasƒ±: {str(e)}")
                    cart_button = None

                # Buton bulunamazsa d√∂ng√ºy√º devam ettir
                if not cart_button:
                    logging.warning(f"Sepete ekle butonu bulunamadƒ± veya zaten eklendi: {url}")
                    continue
                
                # Sepete ekle
                driver.execute_script("arguments[0].click();", cart_button)
                print(f"üîç SELENIUM DEBUG: Sepete ekleme butonu tƒ±klandƒ±")
                time.sleep(random.uniform(2, 3))
                
                # Sepet sayfasƒ±na git
                cart_url = "https://www.trendyol.com/sepet"
                driver.get(cart_url)
                print(f"üîç SELENIUM DEBUG: Sepet sayfasƒ±na gidildi")
                
                # Sepet y√ºklenene kadar bekle - satƒ±≈ü verisi odaklƒ±
                cart_loaded = False
                cart_wait_selectors = [
                    ".order-count-text",  # Direkt satƒ±≈ü verisi
                    ".social-proof-label",  # Satƒ±≈ü container'ƒ±
                    "[class*='social-proof']",
                    ".cart-item",
                    ".basket-item", 
                    "[class*='cart']",
                    "body"  # fallback
                ]
                
                for selector in cart_wait_selectors:
                    try:
                        element = WebDriverWait(driver, 3).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                        )
                        print(f"üîç SELENIUM DEBUG: Sepet y√ºklendi ({selector}): {element.text[:50] if element.text else 'bo≈ü'}")
                        cart_loaded = True
                        break
                    except:
                        print(f"üîç SELENIUM DEBUG: Sepet selector bulunamadƒ±: {selector}")
                        continue
                
                if not cart_loaded:
                    print(f"üîç SELENIUM DEBUG: Sepet y√ºklenemedi, devam ediliyor...")
                
                time.sleep(2)  # Extra wait
                
                time.sleep(random.uniform(1, 2))
                
                # 3 g√ºnl√ºk satƒ±≈ü verisini ara
                sales_selectors = [
                    '.order-count-text',  # YENƒ∞: "24 tanesi satƒ±ldƒ±" i√ßin
                    'p[class*="order-count"]',  # YENƒ∞
                    '.social-proof-label p',  # YENƒ∞
                    'div[class*="social-proof"] p',  # YENƒ∞
                    '*[class*="order-count-text"]',  # YENƒ∞
                    '.sales-count',
                    '.last-sold',
                    '[data-testid="sales-info"]',
                    '*[class*="sold"]',
                    '*[class*="sales"]'
                ]
                
                sales_3day = None
                page_source = driver.page_source
                
                # Sayfada satƒ±≈ü pattern'lerini ara
                sales_patterns = [
                    r'(\d+)\s*tanesi\s*satƒ±ldƒ±',  # YENƒ∞: "24 tanesi satƒ±ldƒ±"
                    r'(\d+)\s*adet\s*satƒ±ldƒ±',   # YENƒ∞: "24 adet satƒ±ldƒ±"
                    r'(\d+)\s*adet.*?3.*?g√ºn',
                    r'3.*?g√ºn.*?(\d+)\s*adet',
                    r'Son.*?3.*?g√ºn.*?(\d+)',
                    r'(\d+).*?satƒ±ldƒ±.*?3.*?g√ºn'
                ]
                
                print(f"üîç SELENIUM DEBUG: Sepet sayfasƒ±nda satƒ±≈ü verisi aranƒ±yor...")
                
                # Debug: Sayfa source'unu kontrol et
                page_source = driver.page_source
                if "tanesi satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'tanesi satƒ±ldƒ±' metni sayfada var!")
                elif "adet satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'adet satƒ±ldƒ±' metni sayfada var!")
                elif "satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'satƒ±ldƒ±' metni sayfada var!")
                else:
                    print(f"üîç SELENIUM DEBUG: Satƒ±≈ü metni bulunamadƒ±, sayfa i√ßeriƒüi:")
                    print(f"üîç SELENIUM DEBUG: ƒ∞lk 1000 karakter: {page_source[:1000]}")
                
                for pattern in sales_patterns:
                    match = re.search(pattern, page_source, re.IGNORECASE | re.DOTALL)
                    if match:
                        try:
                            sales_3day = int(match.group(1))
                            print(f"üîç SELENIUM DEBUG: Pattern ile satƒ±≈ü bulundu ({pattern}): {sales_3day}")
                            break
                        except (ValueError, IndexError):
                            continue
                
                # Eƒüer pattern match yapmadƒ±ysa, DOM elementlerini kontrol et
                if sales_3day is None:
                    print(f"üîç SELENIUM DEBUG: Pattern bulunamadƒ±, DOM elementleri kontrol ediliyor...")
                    for selector in sales_selectors:
                        try:
                            elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            for element in elements:
                                text = element.text.strip()
                                print(f"üîç SELENIUM DEBUG: Element text ({selector}): '{text}'")
                                
                                # "tanesi satƒ±ldƒ±" veya "adet satƒ±ldƒ±" ara
                                if 'tanesi satƒ±ldƒ±' in text or 'adet satƒ±ldƒ±' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"üîç SELENIUM DEBUG: DOM'dan satƒ±≈ü bulundu ({selector}): {sales_3day}")
                                        break
                                # Eski format: "3 g√ºn" ara
                                elif '3' in text and 'g√ºn' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"üîç SELENIUM DEBUG: DOM'dan 3 g√ºnl√ºk satƒ±≈ü bulundu ({selector}): {sales_3day}")
                                        break
                            if sales_3day:
                                break
                        except Exception as e:
                            print(f"üîç SELENIUM DEBUG: DOM element hatasƒ± ({selector}): {str(e)}")
                            continue
                
                if sales_3day is not None:
                    print(f"üîç SELENIUM DEBUG: Ba≈üarƒ±lƒ±! Satƒ±≈ü verisi: {sales_3day}")
                    return sales_3day
                else:
                    print(f"üîç SELENIUM DEBUG: Satƒ±≈ü verisi bulunamadƒ±")
                    logging.warning(f"3 g√ºnl√ºk satƒ±≈ü verisi bulunamadƒ±: {url}")
                    
            except TimeoutException:
                logging.warning(f"Timeout - sepet verisi alƒ±namadƒ± (deneme {attempt + 1}): {url}")
                continue
            except Exception as e:
                logging.error(f"Sepet verisi hatasƒ± (deneme {attempt + 1}) - {url}: {str(e)}")
                continue
        
        return None
        
    except Exception as e:
        logging.error(f"Selenium sepet verisi hatasƒ± - {url}: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_single_product(product_link_id: int, product_url: str, scraped_by: str) -> bool:
    """
    Tek bir √ºr√ºn i√ßin complete scraping yapar
    """
    try:
        print(f"üîç DEBUG: √úr√ºn scraping ba≈ülatƒ±lƒ±yor: {product_url}")
        
        # Selenium ile veri √ßek
        basic_info = scrape_product_with_selenium(product_url)
        if not basic_info:
            print(f"üîç DEBUG: Selenium veri √ßekme ba≈üarƒ±sƒ±z: {product_url}")
            return False
        
        print(f"üîç DEBUG: Kaydedilecek veri: {basic_info}")
        
        # Veri kaydet - SALES ALANLARI EKLENDƒ∞
        print(f"üîç PROD DEBUG: save_product_data √ßaƒürƒ±lƒ±yor...")
        print(f"üîç PROD DEBUG: product_link_id: {product_link_id}")
        print(f"üîç PROD DEBUG: product_image_url: {basic_info.get('image_url', 'None')}")
        logging.info(f"PROD DEBUG: Veri kaydediliyor - Link ID: {product_link_id}, Image URL var mƒ±: {bool(basic_info.get('image_url'))}")


        success = save_product_data(
            product_link_id=product_link_id,
            seller_name=basic_info.get('seller', 'Bilinmiyor'),
            product_title=basic_info.get('title', ''),
            price=basic_info.get('price', 0.0),
            comment_count=basic_info.get('comments', 0),
            question_count=basic_info.get('questions', 0), 
            rating=basic_info.get('rating', 0.0),
            sales_3day=basic_info.get('sales_3day'),  # ‚úÖ Bu yeterli
            seller_rating=basic_info.get('seller_rating', 0.0),
            scraped_by=scraped_by,
            product_image_url=basic_info.get('image_url')
            # daily_estimated_sales KALDIRDIK - zaten fonksiyonda hesaplanƒ±yor!
        )
        
        # Debug √ßƒ±ktƒ±larƒ± SONRA ekle
        if success:
            print(f"‚úÖ PROD DEBUG: save_product_data ba≈üarƒ±lƒ± - Image URL kaydedildi mi: {bool(basic_info.get('image_url'))}")
            logging.info(f"PROD DEBUG: Veri kaydetme ba≈üarƒ±lƒ± - Link ID: {product_link_id}")
            print(f"üîç DEBUG: √úr√ºn scraping ba≈üarƒ±lƒ±: {product_url}")
            return True
        else:
            print(f"‚ùå PROD DEBUG: save_product_data ba≈üarƒ±sƒ±z!")
            logging.error(f"PROD DEBUG: Veri kaydetme ba≈üarƒ±sƒ±z - Link ID: {product_link_id}")
            print(f"üîç DEBUG: Veri kaydetme hatasƒ±: {product_url}")
            return False
            
    except Exception as e:
        print(f"üîç DEBUG: √úr√ºn scraping exception: {product_url} - {str(e)}")
        return False

def update_scraping_status(is_running: bool = None, progress: int = None, 
                          total: int = None, current_item: str = None,
                          started_by: str = None, error: str = None,
                          success_count: int = None, failed_count: int = None):
    """Scraping durumunu g√ºnceller"""
    global scraping_status
    
    with scraping_lock:
        if is_running is not None:
            scraping_status['is_running'] = is_running
            if is_running:
                scraping_status['start_time'] = time.time()
                scraping_status['errors'] = []
                scraping_status['success_count'] = 0
                scraping_status['failed_count'] = 0
            
        if progress is not None:
            scraping_status['current_progress'] = progress
            
        if total is not None:
            scraping_status['total_items'] = total
            
        if current_item is not None:
            scraping_status['current_item'] = current_item
            
        if started_by is not None:
            scraping_status['started_by'] = started_by
            
        if error is not None:
            scraping_status['errors'].append(error)
            
        if success_count is not None:
            scraping_status['success_count'] = success_count
            
        if failed_count is not None:
            scraping_status['failed_count'] = failed_count

def get_scraping_status() -> Dict:
    """Mevcut scraping durumunu d√∂nd√ºr√ºr"""
    with scraping_lock:
        status = scraping_status.copy()
        if status['start_time']:
            status['elapsed_time'] = time.time() - status['start_time']
        else:
            status['elapsed_time'] = 0
        return status

def start_single_product_scraping(product_link_id: int, product_url: str, scraped_by: str):
    """
    Tek √ºr√ºn i√ßin arka planda scraping ba≈ülatƒ±r (yeni √ºr√ºn eklendiƒüinde)
    """
    def scrape_worker():
        try:
            success = scrape_single_product(product_link_id, product_url, scraped_by)
            if success:
                logging.info(f"Tek √ºr√ºn scraping tamamlandƒ±: {product_url}")
            else:
                logging.error(f"Tek √ºr√ºn scraping ba≈üarƒ±sƒ±z: {product_url}")
        except Exception as e:
            logging.error(f"Tek √ºr√ºn scraping worker hatasƒ±: {str(e)}")
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_manual_update(username: str) -> bool:
    """
    Manuel g√ºncelleme ba≈ülatƒ±r (Admin yetkisi gerekli)
    T√ºm aktif √ºr√ºnler i√ßin scraping yapar
    """
    def manual_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # T√ºm aktif √ºr√ºnleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Manuel g√ºncelleme ba≈ülatƒ±ldƒ±: {total_products} √ºr√ºn")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu g√ºncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"√úr√ºn {i+1}/{total_products}: {product_url[:50]}..."
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Scraping hatasƒ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Bekleme s√ºresi
                time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
            
            logging.info(f"Manuel g√ºncelleme tamamlandƒ±: {success_count}/{total_products} ba≈üarƒ±lƒ±")
            
        except Exception as e:
            error_msg = f"Manuel g√ºncelleme hatasƒ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # Eƒüer ba≈üka bir scraping devam ediyorsa ba≈ülatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, yeni i≈ülem ba≈ülatƒ±lmadƒ±")
        return False
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=manual_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def start_scheduled_update(username: str = "scheduler") -> bool:
    """
    Zamanlanmƒ±≈ü g√ºncelleme ba≈ülatƒ±r
    """
    def scheduled_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # T√ºm aktif √ºr√ºnleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Otomatik g√ºncelleme ba≈ülatƒ±ldƒ±: {total_products} √ºr√ºn")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu g√ºncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"Otomatik: √úr√ºn {i+1}/{total_products}"
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Otomatik scraping hatasƒ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Otomatik g√ºncellemede daha uzun bekleme
                time.sleep(random.uniform(REQUEST_DELAY_MIN + 2, REQUEST_DELAY_MAX + 3))
            
            logging.info(f"Otomatik g√ºncelleme tamamlandƒ±: {success_count}/{total_products} ba≈üarƒ±lƒ±")
            
        except Exception as e:
            error_msg = f"Otomatik g√ºncelleme hatasƒ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # Eƒüer ba≈üka bir scraping devam ediyorsa ba≈ülatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, otomatik i≈ülem atlandƒ±")
        return False
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=scheduled_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def is_scraping_running() -> bool:
    """Scraping i≈üleminin devam edip etmediƒüini kontrol eder"""
    return scraping_status['is_running']

def get_scraping_statistics() -> Dict:
    """
    Scraping istatistiklerini getirir
    """
    try:
        product_stats = get_product_statistics()
        scraping_stats = get_scraping_status()
        
        return {
            'product_stats': product_stats,
            'scraping_status': scraping_stats
        }
        
    except Exception as e:
        logging.error(f"Scraping istatistik hatasƒ±: {str(e)}")
        return {}

# Test fonksiyonu
def test_single_scraping(url: str):
    """Tek bir URL i√ßin test scraping"""
    logging.info(f"Test scraping ba≈ülatƒ±lƒ±yor: {url}")
    
    basic_info = scrape_product_basic_info(url)
    print("Temel bilgiler:", basic_info)
    
    sales_data = scrape_cart_sales_data(url)
    print("3 g√ºnl√ºk satƒ±≈ü:", sales_data)
    
    return basic_info, sales_data