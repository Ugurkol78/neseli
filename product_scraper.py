"""
√úr√ºn ƒ∞zleme ve Analiz Mod√ºl√º - Web Scraping
Selenium ve BeautifulSoup ile Trendyol √ºr√ºn verilerini √ßeker
3 g√ºnl√ºk satƒ±≈ü verisi i√ßin sepet i≈ülemleri yapar
"""

import requests
from bs4 import BeautifulSoup
import time
import random
import logging
import threading
from typing import Dict, Optional, List
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import re
# Mevcut import'larƒ±n altƒ±na bu satƒ±rƒ± ekleyin:
from webdriver_manager.chrome import ChromeDriverManager

from product_tracking import (
    get_active_product_links, save_product_data, 
    get_product_statistics
)

# Scraping ayarlarƒ±
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

REQUEST_DELAY_MIN = 3  # Minimum bekleme s√ºresi (saniye)
REQUEST_DELAY_MAX = 7  # Maximum bekleme s√ºresi (saniye)
REQUEST_TIMEOUT = 20   # ƒ∞stek timeout s√ºresi (saniye)

# Global scraping durumu
scraping_status = {
    'is_running': False,
    'current_progress': 0,
    'total_items': 0,
    'current_item': '',
    'started_by': '',
    'start_time': None,
    'errors': [],
    'success_count': 0,
    'failed_count': 0
}

scraping_lock = threading.Lock()

def parse_turkish_price(price_text: str) -> float:
    """
    T√ºrk√ße fiyat formatƒ±nƒ± parse eder
    "2.959 TL" -> 2959.0
    "2.959,50 TL" -> 2959.5
    "59,90 TL" -> 59.9
    """
    # Sadece rakam, nokta ve virg√ºl bƒ±rak
    price_clean = re.sub(r'[^\d,.]', '', price_text).strip()
    
    if not price_clean:
        return 0.0
    
    # T√ºrk√ße format kontrol√º
    if '.' in price_clean and ',' in price_clean:
        # "2.959,50" formatƒ± - nokta bin ayracƒ±, virg√ºl ondalƒ±k
        price_clean = price_clean.replace('.', '').replace(',', '.')
    elif '.' in price_clean:
        # Sadece nokta var - bin ayracƒ± mƒ± ondalƒ±k mƒ±?
        parts = price_clean.split('.')
        if len(parts) == 2 and len(parts[1]) == 3:
            # "2.959" - bin ayracƒ± (3 haneli)
            price_clean = price_clean.replace('.', '')
        # Aksi halde ondalƒ±k ayracƒ± olarak bƒ±rak
    elif ',' in price_clean:
        # Sadece virg√ºl var - ondalƒ±k ayracƒ±
        price_clean = price_clean.replace(',', '.')
    
    try:
        return float(price_clean)
    except ValueError:
        return 0.0

def get_random_headers() -> Dict[str, str]:
    """Rastgele User-Agent ile header olu≈üturur"""
    return {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
    }

def setup_chrome_driver() -> webdriver.Chrome:
    """Chrome WebDriver'ƒ± headless modda kuruluma hazƒ±rlar"""
    print(f"üîç PROD DEBUG: Chrome driver kuruluyor...")
    
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument(f'--user-agent={random.choice(USER_AGENTS)}')
    
    # VPS i√ßin ayarlar
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    
    print(f"üîç PROD DEBUG: Chrome options ayarlandƒ± (headless mode)")
    
    try:
        # Manuel path kullan
        service = Service('/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"‚úÖ PROD DEBUG: Chrome driver ba≈üarƒ±yla kuruldu")
        return driver
    except Exception as e:
        print(f"‚ùå PROD DEBUG: Chrome driver kurulum hatasƒ±: {str(e)}")
        logging.error(f"PROD DEBUG: Chrome driver hatasƒ±: {str(e)}")
        raise

def scrape_product_basic_info(url: str) -> Optional[Dict[str, any]]:
    """
    BeautifulSoup ile temel √ºr√ºn bilgilerini √ßeker (hƒ±zlƒ±)
    Returns: {'title': str, 'seller': str, 'price': float, 'rating': float, 'comments': int, 'questions': int, 'image_url': str}
    """
    try:
        headers = get_random_headers()
        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        
        # DEBUG: Sayfa i√ßeriƒüini kontrol et
        print(f"üîç DEBUG: Sayfa ba≈ülƒ±ƒüƒ±: {soup.title.string if soup.title else 'Ba≈ülƒ±k yok'}")
        print(f"üîç DEBUG: Sayfa uzunluƒüu: {len(response.text)} karakter")
        
        # DEBUG: Belirli elementleri ara
        rating_element = soup.select_one('.reviews-summary-average-rating')
        print(f"üîç DEBUG: Rating element bulundu mu? {rating_element is not None}")
        if rating_element:
            print(f"üîç DEBUG: Rating deƒüeri: {rating_element.get_text(strip=True)}")
        
        comment_element = soup.select_one('.reviews-summary-reviews-summary a span')
        print(f"üîç DEBUG: Comment element bulundu mu? {comment_element is not None}")
        if comment_element:
            print(f"üîç DEBUG: Comment deƒüeri: {comment_element.get_text(strip=True)}")


        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # √úr√ºn ba≈ülƒ±ƒüƒ±
        title_selectors = [
            'h1[data-testid="product-title"]',
            'h1.product-title',
            'h1.pr-new-br',
            'h1'
        ]
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['title'] = element.get_text(separator=' ', strip=True)
                break
        
        # Fiyat
        price_selectors = [
            '.campaign-price-container.default',  # YENƒ∞: Campaign container
            '.prc-dsc',
            '.prc-slg', 
            '.product-price .prc-dsc',
            '[data-testid="price-current-price"]',
            '.price-current',
            'span[class*="price"]',
            '.prc-cntr .prc-dsc',  # Yeni
            '.price-container span',  # Yeni
            'div[class*="price"] span',  # Yeni
            '.product-price span:last-child',  # Yeni
            'span[data-testid*="price"]'  # Yeni
        ]
        for selector in price_selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                
                # Campaign container i√ßin √∂zel parsing
                if selector == '.campaign-price-container.default' and '\n' in price_text:
                    print(f"üîç DEBUG: Campaign container parsing: '{price_text}'")
                    
                    # Sadece ger√ßek fiyat satƒ±rlarƒ±nƒ± al
                    lines = [line.strip() for line in price_text.split('\n') if line.strip()]
                    valid_prices = []
                    
                    for line in lines:
                        if 'TL' in line and any(char.isdigit() for char in line):
                            line_lower = line.lower()
                            # Kampanya a√ßƒ±klamasƒ± deƒüilse
                            if 'indirim' not in line_lower and 'ye' not in line_lower and 'sepette' not in line_lower:
                                test_price = parse_turkish_price(line)  # YENƒ∞: Turkish price parser
                                if test_price > 0:  # YENƒ∞: 0'dan b√ºy√ºk kontrol√º
                                    if 1 <= test_price <= 1000000:  # YENƒ∞: Range d√ºzeltildi
                                        valid_prices.append(test_price)
                    
                    if valid_prices:
                        result['price'] = min(valid_prices)  # En k√º√ß√ºk (indirimli) fiyat
                        print(f"üîç DEBUG: Campaign price selected: {result['price']} from {valid_prices}")
                        break
                
                # Diƒüer selector'lar i√ßin eski parsing
                else:
                    price_clean = ''.join(filter(lambda x: x.isdigit() or x == ',', price_text))
                    if price_clean:
                        try:
                            result['price'] = float(price_clean.replace(',', '.'))
                            break
                        except ValueError:
                            continue

        
        # Satƒ±cƒ± adƒ±
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]'
        ]
        for selector in seller_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                result['seller'] = element.get_text(strip=True)
                break
        
        
        # Puan
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-line-count',
            '.stars-container .rating',
            '[data-testid="product-rating"]'
        ]
        for selector in rating_selectors:
            element = soup.select_one(selector)
            if element:
                rating_text = element.get_text(strip=True)
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    try:
                        result['rating'] = float(rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        # Yorum sayƒ±sƒ±  
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.rating-line-count',
            '.comments-summary .rating-line-count',
            '[data-testid="reviews-count"]',
            'a[data-testid="questions-summary-link"] span'
        ]
        for selector in comment_selectors:
            element = soup.select_one(selector)
            if element:
                comment_text = element.get_text(strip=True)
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    break
        
        # Soru sayƒ±sƒ±
        question_selectors = [
            'a[data-testid="questions-summary-link"] span:last-child',
            '.qa-section-header',
            '.questions-answers .header',
            '[data-testid="questions-count"]'
        ]
        for selector in question_selectors:
            element = soup.select_one(selector)
            if element:
                question_text = element.get_text(strip=True)
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    break
        
        # √úr√ºn resmi
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]'
        ]
        for selector in image_selectors:
            element = soup.select_one(selector)
            if element and element.get('src'):
                result['image_url'] = element.get('src')
                break
        
        # Satƒ±cƒ± puanƒ± (varsa)
        seller_rating_selectors = [
            '.score-badge',
            '._body_03c70b5',
            '.merchant-rating',
            '.seller-score',
            '[data-testid="seller-rating"]'
        ]
        for selector in seller_rating_selectors:
            element = soup.select_one(selector)
            if element:
                seller_rating_text = element.get_text(strip=True)
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        break
                    except ValueError:
                        continue
        
        return result
        
    except requests.exceptions.RequestException as e:
        logging.error(f"Request hatasƒ± - {url}: {str(e)}")
        return None
    except Exception as e:
        logging.error(f"Scraping hatasƒ± - {url}: {str(e)}")
        return None


def scrape_product_with_selenium(url: str) -> Optional[Dict[str, any]]:
    """
    Selenium ile JavaScript y√ºkl√º sayfadan veri √ßeker
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        print(f"üîç SELENIUM DEBUG: Sayfaya gidiliyor: {url}")
        driver.get(url)
        
        # Sayfa y√ºklenene kadar bekle
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScript'in tam y√ºklenmesi i√ßin bekleme
        time.sleep(5)
        
        # Sayfayƒ± a≈üaƒüƒ± kaydƒ±r (lazy loading i√ßin)
        driver.execute_script("window.scrollTo(0, 1000);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        result = {
            'title': None,
            'seller': None, 
            'price': None,
            'rating': None,
            'comments': 0,
            'questions': 0,
            'image_url': None,
            'seller_rating': None
        }
        
        # Title √ßek (her zaman √ßalƒ±≈üƒ±yor)
        try:
            title_selectors = ['h1', '[data-testid="product-title"]', '.product-title']
            for selector in title_selectors:
                try:
                    title_element = driver.find_element(By.CSS_SELECTOR, selector)
                    result['title'] = title_element.text.strip()
                    print(f"üîç SELENIUM DEBUG: Title bulundu ({selector}): {result['title'][:50]}...")
                    break
                except:
                    continue
        except Exception as e:
            print(f"üîç SELENIUM DEBUG: Title hatasƒ±: {str(e)}")
        
        # Rating √ßek - √áoklu selector deneme
        rating_selectors = [
            '.reviews-summary-average-rating',
            '.rating-score',
            '.product-rating-score',
            '[data-testid="product-rating"]',
            '.stars-container .rating',
            '.review-rating',
            'span[class*="rating"]',
            'div[class*="rating"]'
        ]
        
        for selector in rating_selectors:
            try:
                rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                rating_text = rating_element.text.strip()
                rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                if rating_match:
                    result['rating'] = float(rating_match.group(1).replace(',', '.'))
                    print(f"üîç SELENIUM DEBUG: Rating bulundu ({selector}): {result['rating']}")
                    break
            except:
                continue
        
        if not result['rating']:
            print("üîç SELENIUM DEBUG: Rating bulunamadƒ± - t√ºm selector'lar denendi")
        
        # Comment count √ßek - √áoklu selector deneme
        comment_selectors = [
            '.reviews-summary-reviews-summary a span:first-child',
            '.review-count',
            '.comments-count',
            '[data-testid="reviews-count"]',
            '.rating-line-count',
            'a[href*="yorum"] span',
            'span[class*="review"]',
            'div[class*="review"] span'
        ]
        
        for selector in comment_selectors:
            try:
                comment_element = driver.find_element(By.CSS_SELECTOR, selector)
                comment_text = comment_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Comment element text ({selector}): '{comment_text}'")
                
                # Sayƒ± √ßƒ±karma
                comment_match = re.search(r'(\d+)', comment_text.replace('.', '').replace(',', ''))
                if comment_match:
                    result['comments'] = int(comment_match.group(1))
                    print(f"üîç SELENIUM DEBUG: Comment count bulundu ({selector}): {result['comments']}")
                    break
            except:
                continue
        
        if not result['comments']:
            print("üîç SELENIUM DEBUG: Comment count bulunamadƒ± - t√ºm selector'lar denendi")
        
        # Question count √ßek
        question_selectors = [
            'a[data-testid="questions-summary-link"] span',  # YENƒ∞: En doƒüru selector
            '.questions-summary-questions-summary span',     # YENƒ∞: Class selector
            'a[class*="questions-summary"] span',            # YENƒ∞: Partial class
            'a[href*="saticiya-sor"] span',                  # YENƒ∞: URL-based
            'a[data-testid="questions-summary-link"] span:last-child',  # YENƒ∞: Son span
            '.questions-summary-questions-summary span b',   # YENƒ∞: Bold i√ßindeki sayƒ±
            'a[data-testid="questions-summary-link"] b',     # YENƒ∞: Bold tag
            'a[data-testid="questions-summary-link"] span:last-child',
            '.questions-count',
            '.qa-count',
            '[data-testid="questions-count"]',
            'a[href*="soru"] span'
        ]

        for selector in question_selectors:
            try:
                question_element = driver.find_element(By.CSS_SELECTOR, selector)
                question_text = question_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Question element text ({selector}): '{question_text}'")
                
                # Sayƒ± √ßƒ±karma - "202 Soru-Cevap" formatƒ±ndan
                question_match = re.search(r'(\d+)', question_text.replace('.', '').replace(',', ''))
                if question_match:
                    result['questions'] = int(question_match.group(1))
                    print(f"üîç SELENIUM DEBUG: Question count bulundu ({selector}): {result['questions']}")
                    break
            except:
                continue
        
        # Price √ßek - Geli≈ümi≈ü selector'lar
        price_selectors = [
            '.campaign-price-container.default',  # YENƒ∞: Campaign container
            '.prc-dsc',
            '.prc-slg', 
            '.product-price .prc-dsc',
            '[data-testid="price-current-price"]',
            '.price-current',
            'span[class*="price"]',
            '.prc-cntr .prc-dsc',  # Yeni
            '.price-container span',  # Yeni
            'div[class*="price"] span',  # Yeni
            '.product-price span:last-child',  # Yeni
            'span[data-testid*="price"]'  # Yeni
        ]

        for selector in price_selectors:
            try:
                price_element = driver.find_element(By.CSS_SELECTOR, selector)
                price_text = price_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Price element text ({selector}): '{price_text}'")
                
                # Campaign container i√ßin √∂zel parsing - G√úNCELLENEN VERSƒ∞YON
                if selector == '.campaign-price-container.default' and '\n' in price_text:
                    print(f"üîç SELENIUM DEBUG: Campaign container parsing...")
                    
                    # Sadece ger√ßek fiyat satƒ±rlarƒ±nƒ± al
                    lines = [line.strip() for line in price_text.split('\n') if line.strip()]
                    valid_prices = []
                    
                    print(f"üîç SELENIUM DEBUG: Campaign lines: {lines}")  # DEBUG: t√ºm satƒ±rlarƒ± g√∂ster
                    
                    for line in lines:
                        print(f"üîç SELENIUM DEBUG: Processing line: '{line}'")
                        
                        if 'TL' in line and any(char.isdigit() for char in line):
                            line_lower = line.lower()
                            print(f"üîç SELENIUM DEBUG: Line has TL and digits: '{line}'")
                            
                            # Kampanya a√ßƒ±klamasƒ± deƒüilse - DAHA AZ KISITLAYICI
                            if 'indirim' not in line_lower and 'ye' not in line_lower:  # 'sepette' kaldƒ±rdƒ±k
                                test_price = parse_turkish_price(line)  # YENƒ∞: Turkish price parser
                                print(f"üîç SELENIUM DEBUG: Parsed price: {test_price}")
                                
                                if test_price > 0:  # YENƒ∞: 0'dan b√ºy√ºk kontrol√º
                                    if 1 <= test_price <= 1000000:  # YENƒ∞: Range d√ºzeltildi
                                        valid_prices.append(test_price)
                                        print(f"üîç SELENIUM DEBUG: Valid price added: {test_price}")
                                    else:
                                        print(f"üîç SELENIUM DEBUG: Price out of range: {test_price}")
                                else:
                                    print(f"üîç SELENIUM DEBUG: Price parse failed: {test_price}")
                            else:
                                print(f"üîç SELENIUM DEBUG: Line filtered out (campaign text): '{line}'")
                        else:
                            print(f"üîç SELENIUM DEBUG: Line has no TL or digits: '{line}'")

                # Diƒüer selector'lar i√ßin de turkish parser kullan:
                else:
                    test_price = parse_turkish_price(price_text)  # YENƒ∞: Turkish price parser
                    if test_price > 0:  # YENƒ∞: 0'dan b√ºy√ºk kontrol√º
                        result['price'] = test_price
                        print(f"üîç SELENIUM DEBUG: Price bulundu ({selector}): {result['price']}")
                        break
        
        # Seller name √ßek
        seller_selectors = [
            '.product-description-market-place',
            'span.product-description-market-place',
            '.merchant-name',
            '[class*="merchant-name"]',
            '.seller-name'
        ]
        
        for selector in seller_selectors:
            try:
                seller_element = driver.find_element(By.CSS_SELECTOR, selector)
                result['seller'] = seller_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Seller bulundu ({selector}): {result['seller']}")
                break
            except:
                continue
        
        # Seller rating √ßek - G√úNCELLENMƒ∞≈û SELECTOR'LAR
        seller_rating_selectors = [
            '.score-badge',                              # Ana selector
            '._body_03c70b5',                           # YENƒ∞: Spesifik class
            'div[class*="_body_03c70b5"]',              # YENƒ∞: Partial class match
            'div.score-badge',                          # YENƒ∞: Div ile score-badge
            '[class*="score-badge"]',                   # YENƒ∞: Partial score-badge
            'div[style*="background-color: rgb(4, 155, 36)"]',  # YENƒ∞: Ye≈üil background
            'div[style*="background-color: rgb"]',      # YENƒ∞: Herhangi bir background color
            '.merchant-rating',                         # Eski selector
            '.seller-score',                           # Eski selector
            '[data-testid="seller-rating"]',           # Eski selector
            'span[class*="rating"]',                   # Eski selector
            'div[class*="rating"]'                     # Eski selector
        ]

        for selector in seller_rating_selectors:
            try:
                seller_rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                seller_rating_text = seller_rating_element.text.strip()
                print(f"üîç SELENIUM DEBUG: Seller rating element text ({selector}): '{seller_rating_text}'")
                
                # Sayƒ± √ßƒ±karma - "9.4" formatƒ±ndan
                seller_rating_match = re.search(r'(\d+[,.]?\d*)', seller_rating_text)
                if seller_rating_match:
                    try:
                        result['seller_rating'] = float(seller_rating_match.group(1).replace(',', '.'))
                        print(f"üîç SELENIUM DEBUG: Seller rating bulundu ({selector}): {result['seller_rating']}")
                        break
                    except ValueError:
                        continue
            except Exception as e:
                print(f"üîç SELENIUM DEBUG: Seller rating hatasƒ± ({selector}): {str(e)}")
                continue

        if not result['seller_rating']:
            print("üîç SELENIUM DEBUG: Seller rating bulunamadƒ± - t√ºm selector'lar denendi")
            
            # DEBUG: Sayfada score-badge ile ilgili t√ºm elementleri bul
            try:
                all_score_elements = driver.find_elements(By.CSS_SELECTOR, '*[class*="score"]')
                print(f"üîç SELENIUM DEBUG: Score i√ßeren {len(all_score_elements)} element bulundu:")
                for i, elem in enumerate(all_score_elements[:5]):  # ƒ∞lk 5 tanesini g√∂ster
                    try:
                        print(f"  {i+1}. {elem.tag_name} - class='{elem.get_attribute('class')}' - text='{elem.text.strip()}'")
                    except:
                        pass
            except:
                print("üîç SELENIUM DEBUG: Score element aramasƒ± ba≈üarƒ±sƒ±z")
        
        # Image URL √ßek
        image_selectors = [
            '.product-images img',
            '.gallery-modal img',
            'img[data-testid="product-image"]',
            '.product-image img'
        ]

        print(f"üîç PROD DEBUG: Image selector aramasƒ± ba≈ülƒ±yor...")
        logging.info(f"PROD DEBUG: Image URL √ßekme ba≈ülƒ±yor - URL: {url}")

        for i, selector in enumerate(image_selectors):
            try:
                print(f"üîç PROD DEBUG: Image selector {i+1}/{len(image_selectors)} deneniyor: {selector}")
                image_element = driver.find_element(By.CSS_SELECTOR, selector)
                image_url = image_element.get_attribute('src')
                print(f"üîç PROD DEBUG: Element bulundu! Src attribute: {image_url}")
                
                if image_url:
                    result['image_url'] = image_url
                    print(f"‚úÖ PROD DEBUG: Image URL ba≈üarƒ±yla √ßekildi ({selector}): {image_url[:100]}...")
                    logging.info(f"PROD DEBUG: Image URL ba≈üarƒ±yla elde edildi: {image_url}")
                    break
                else:
                    print(f"‚ö†Ô∏è PROD DEBUG: Element bulundu ama src attribute bo≈ü ({selector})")
            except Exception as selector_error:
                print(f"‚ùå PROD DEBUG: Image selector hatasƒ± ({selector}): {str(selector_error)}")
                continue

        if not result.get('image_url'):
            print(f"‚ùå PROD DEBUG: Hi√ßbir image selector √ßalƒ±≈ümadƒ±! T√ºm selector'lar denendi.")
            logging.warning(f"PROD DEBUG: Image URL bulunamadƒ± - URL: {url}")
            
            # DEBUG: Sayfada img elementlerini ara
            try:
                all_images = driver.find_elements(By.TAG_NAME, 'img')
                print(f"üîç PROD DEBUG: Sayfada toplam {len(all_images)} img elementi bulundu")
                
                # ƒ∞lk 3 img elementinin src'sini g√∂ster
                for i, img in enumerate(all_images[:3]):
                    try:
                        src = img.get_attribute('src')
                        print(f"üîç PROD DEBUG: Img {i+1} src: {src[:100] if src else 'None'}...")
                    except:
                        print(f"üîç PROD DEBUG: Img {i+1} src okunamadƒ±")
                        
            except Exception as img_debug_error:
                print(f"‚ùå PROD DEBUG: Img elementleri debug hatasƒ±: {str(img_debug_error)}")

        print(f"üîç PROD DEBUG: Image URL final result: {result.get('image_url', 'None')}")
        
        # Sales data √ßek (sepet i≈ülemi)
        if not result.get('sales_3day'):
            try:
                print(f"üîç SELENIUM DEBUG: Sales data √ßekiliyor...")
                sales_data = scrape_cart_sales_data(url)
                if sales_data:
                    result['sales_3day'] = sales_data
                    result['daily_estimated_sales'] = sales_data / 3.0
                    print(f"üîç SELENIUM DEBUG: Sales data eklendi: {sales_data}")
                else:
                    print(f"üîç SELENIUM DEBUG: Sales data bulunamadƒ±")
            except Exception as e:
                print(f"üîç SELENIUM DEBUG: Sales data hatasƒ±: {str(e)}")
        
        print(f"üîç SELENIUM DEBUG: Final result: {result}")
        return result
        
    except Exception as e:
        print(f"üîç SELENIUM DEBUG: Genel hata: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass


def scrape_cart_sales_data(url: str, max_retries: int = 2) -> Optional[int]:
    """
    Selenium ile sepete ekleme i≈ülemi yaparak 3 g√ºnl√ºk satƒ±≈ü verisini √ßeker
    Returns: sales_3day (int) or None
    """
    driver = None
    try:
        driver = setup_chrome_driver()
        
        for attempt in range(max_retries):
            try:
                logging.info(f"Sepet verisi √ßekiliyor (deneme {attempt + 1}): {url}")
                
                # √ñnce sepeti temizle
                try:
                    print(f"üîç SELENIUM DEBUG: Sepet temizleniyor...")
                    cart_url = "https://www.trendyol.com/sepet"
                    driver.get(cart_url)
                    time.sleep(2)
                    
                    # Sepetteki √ºr√ºnleri sil
                    delete_buttons = driver.find_elements(By.CSS_SELECTOR, '.remove-item, .delete-item, [class*="remove"], [class*="delete"]')
                    for btn in delete_buttons:
                        try:
                            driver.execute_script("arguments[0].click();", btn)
                            time.sleep(0.5)
                        except:
                            continue
                    
                    print(f"üîç SELENIUM DEBUG: Sepet temizlendi")
                except Exception as e:
                    print(f"üîç SELENIUM DEBUG: Sepet temizleme hatasƒ±: {str(e)}")
                
                # √úr√ºn sayfasƒ±na git
                driver.get(url)
                
                # Sayfa y√ºklenene kadar bekle
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                time.sleep(random.uniform(2, 4))

                # Sayfayƒ± scroll et (sepete ekle butonu g√∂r√ºn√ºr olsun)
                driver.execute_script("window.scrollTo(0, 800);")
                time.sleep(2)
                driver.execute_script("window.scrollTo(0, 400);")
                time.sleep(1)

                print(f"üîç SELENIUM DEBUG: Sayfa scroll edildi, buton aranƒ±yor...")

                # Sepete ekle butonunu bul ve tƒ±kla
                cart_button = None
                
                # Ana buton selector'ƒ±
                main_selector = 'button[data-testid="add-to-cart-button"]'
                
                try:
                    # Butonun var olmasƒ±nƒ± bekle
                    print(f"üîç SELENIUM DEBUG: Sepete ekle butonu aranƒ±yor...")
                    cart_button = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                    )
                    print(f"üîç SELENIUM DEBUG: Buton bulundu: {main_selector}")
                    
                    # Loading'in bitmesini bekle
                    try:
                        WebDriverWait(driver, 5).until_not(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                        )
                        print(f"üîç SELENIUM DEBUG: Loading bitti")
                    except:
                        print(f"üîç SELENIUM DEBUG: Loading timeout - devam ediliyor")
                    
                    # Butonun durumunu kontrol et
                    time.sleep(1)
                    button_text = cart_button.text.strip()
                    print(f"üîç SELENIUM DEBUG: Buton text: '{button_text}'")
                    
                    # Eƒüer "Sepete Eklendi" ise yenile ve bekle
                    if "Eklendi" in button_text:
                        print(f"üîç SELENIUM DEBUG: Buton eklendi durumunda - sayfa yenileniyor...")
                        driver.refresh()
                        time.sleep(3)
                        
                        # Yeniden buton ara
                        cart_button = WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, main_selector))
                        )
                        
                        # Loading bekle
                        try:
                            WebDriverWait(driver, 5).until_not(
                                EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-testid="add-to-cart-button"] [data-testid="loading"]'))
                            )
                        except:
                            pass
                        
                        time.sleep(1)
                        button_text = cart_button.text.strip()
                        print(f"üîç SELENIUM DEBUG: Yenileme sonrasƒ± buton text: '{button_text}'")
                    
                    # Buton durumunu final kontrol
                    if cart_button and cart_button.is_enabled() and "Eklendi" not in button_text:
                        print(f"üîç SELENIUM DEBUG: Sepete ekle butonu hazƒ±r!")
                    else:
                        print(f"üîç SELENIUM DEBUG: Buton hala kullanƒ±lamaz durumda")
                        cart_button = None
                        
                except Exception as e:
                    print(f"üîç SELENIUM DEBUG: Buton bulma hatasƒ±: {str(e)}")
                    cart_button = None

                # Buton bulunamazsa d√∂ng√ºy√º devam ettir
                if not cart_button:
                    logging.warning(f"Sepete ekle butonu bulunamadƒ± veya zaten eklendi: {url}")
                    continue
                
                # Sepete ekle
                driver.execute_script("arguments[0].click();", cart_button)
                print(f"üîç SELENIUM DEBUG: Sepete ekleme butonu tƒ±klandƒ±")
                time.sleep(random.uniform(2, 3))
                
                # Sepet sayfasƒ±na git
                cart_url = "https://www.trendyol.com/sepet"
                driver.get(cart_url)
                print(f"üîç SELENIUM DEBUG: Sepet sayfasƒ±na gidildi")
                
                # Sepet y√ºklenene kadar bekle - satƒ±≈ü verisi odaklƒ±
                cart_loaded = False
                cart_wait_selectors = [
                    ".order-count-text",  # Direkt satƒ±≈ü verisi
                    ".social-proof-label",  # Satƒ±≈ü container'ƒ±
                    "[class*='social-proof']",
                    ".cart-item",
                    ".basket-item", 
                    "[class*='cart']",
                    "body"  # fallback
                ]
                
                for selector in cart_wait_selectors:
                    try:
                        element = WebDriverWait(driver, 3).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                        )
                        print(f"üîç SELENIUM DEBUG: Sepet y√ºklendi ({selector}): {element.text[:50] if element.text else 'bo≈ü'}")
                        cart_loaded = True
                        break
                    except:
                        print(f"üîç SELENIUM DEBUG: Sepet selector bulunamadƒ±: {selector}")
                        continue
                
                if not cart_loaded:
                    print(f"üîç SELENIUM DEBUG: Sepet y√ºklenemedi, devam ediliyor...")
                
                time.sleep(2)  # Extra wait
                
                time.sleep(random.uniform(1, 2))
                
                # 3 g√ºnl√ºk satƒ±≈ü verisini ara
                sales_selectors = [
                    '.order-count-text',  # YENƒ∞: "24 tanesi satƒ±ldƒ±" i√ßin
                    'p[class*="order-count"]',  # YENƒ∞
                    '.social-proof-label p',  # YENƒ∞
                    'div[class*="social-proof"] p',  # YENƒ∞
                    '*[class*="order-count-text"]',  # YENƒ∞
                    '.sales-count',
                    '.last-sold',
                    '[data-testid="sales-info"]',
                    '*[class*="sold"]',
                    '*[class*="sales"]'
                ]
                
                sales_3day = None
                page_source = driver.page_source
                
                # Sayfada satƒ±≈ü pattern'lerini ara
                sales_patterns = [
                    r'(\d+)\s*tanesi\s*satƒ±ldƒ±',  # YENƒ∞: "24 tanesi satƒ±ldƒ±"
                    r'(\d+)\s*adet\s*satƒ±ldƒ±',   # YENƒ∞: "24 adet satƒ±ldƒ±"
                    r'(\d+)\s*adet.*?3.*?g√ºn',
                    r'3.*?g√ºn.*?(\d+)\s*adet',
                    r'Son.*?3.*?g√ºn.*?(\d+)',
                    r'(\d+).*?satƒ±ldƒ±.*?3.*?g√ºn'
                ]
                
                print(f"üîç SELENIUM DEBUG: Sepet sayfasƒ±nda satƒ±≈ü verisi aranƒ±yor...")
                
                # Debug: Sayfa source'unu kontrol et
                page_source = driver.page_source
                if "tanesi satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'tanesi satƒ±ldƒ±' metni sayfada var!")
                elif "adet satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'adet satƒ±ldƒ±' metni sayfada var!")
                elif "satƒ±ldƒ±" in page_source:
                    print(f"üîç SELENIUM DEBUG: 'satƒ±ldƒ±' metni sayfada var!")
                else:
                    print(f"üîç SELENIUM DEBUG: Satƒ±≈ü metni bulunamadƒ±, sayfa i√ßeriƒüi:")
                    print(f"üîç SELENIUM DEBUG: ƒ∞lk 1000 karakter: {page_source[:1000]}")
                
                for pattern in sales_patterns:
                    match = re.search(pattern, page_source, re.IGNORECASE | re.DOTALL)
                    if match:
                        try:
                            sales_3day = int(match.group(1))
                            print(f"üîç SELENIUM DEBUG: Pattern ile satƒ±≈ü bulundu ({pattern}): {sales_3day}")
                            break
                        except (ValueError, IndexError):
                            continue
                
                # Eƒüer pattern match yapmadƒ±ysa, DOM elementlerini kontrol et
                if sales_3day is None:
                    print(f"üîç SELENIUM DEBUG: Pattern bulunamadƒ±, DOM elementleri kontrol ediliyor...")
                    for selector in sales_selectors:
                        try:
                            elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            for element in elements:
                                text = element.text.strip()
                                print(f"üîç SELENIUM DEBUG: Element text ({selector}): '{text}'")
                                
                                # "tanesi satƒ±ldƒ±" veya "adet satƒ±ldƒ±" ara
                                if 'tanesi satƒ±ldƒ±' in text or 'adet satƒ±ldƒ±' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"üîç SELENIUM DEBUG: DOM'dan satƒ±≈ü bulundu ({selector}): {sales_3day}")
                                        break
                                # Eski format: "3 g√ºn" ara
                                elif '3' in text and 'g√ºn' in text:
                                    numbers = re.findall(r'\d+', text)
                                    if numbers:
                                        sales_3day = int(numbers[0])
                                        print(f"üîç SELENIUM DEBUG: DOM'dan 3 g√ºnl√ºk satƒ±≈ü bulundu ({selector}): {sales_3day}")
                                        break
                            if sales_3day:
                                break
                        except Exception as e:
                            print(f"üîç SELENIUM DEBUG: DOM element hatasƒ± ({selector}): {str(e)}")
                            continue
                
                if sales_3day is not None:
                    print(f"üîç SELENIUM DEBUG: Ba≈üarƒ±lƒ±! Satƒ±≈ü verisi: {sales_3day}")
                    return sales_3day
                else:
                    print(f"üîç SELENIUM DEBUG: Satƒ±≈ü verisi bulunamadƒ±")
                    logging.warning(f"3 g√ºnl√ºk satƒ±≈ü verisi bulunamadƒ±: {url}")
                    
            except TimeoutException:
                logging.warning(f"Timeout - sepet verisi alƒ±namadƒ± (deneme {attempt + 1}): {url}")
                continue
            except Exception as e:
                logging.error(f"Sepet verisi hatasƒ± (deneme {attempt + 1}) - {url}: {str(e)}")
                continue
        
        return None
        
    except Exception as e:
        logging.error(f"Selenium sepet verisi hatasƒ± - {url}: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_single_product(product_link_id: int, product_url: str, scraped_by: str) -> bool:
    """
    Tek bir √ºr√ºn i√ßin complete scraping yapar
    """
    try:
        print(f"üîç DEBUG: √úr√ºn scraping ba≈ülatƒ±lƒ±yor: {product_url}")
        
        # Selenium ile veri √ßek
        basic_info = scrape_product_with_selenium(product_url)
        if not basic_info:
            print(f"üîç DEBUG: Selenium veri √ßekme ba≈üarƒ±sƒ±z: {product_url}")
            return False
        
        print(f"üîç DEBUG: Kaydedilecek veri: {basic_info}")
        
        # Veri kaydet - SALES ALANLARI EKLENDƒ∞
        print(f"üîç PROD DEBUG: save_product_data √ßaƒürƒ±lƒ±yor...")
        print(f"üîç PROD DEBUG: product_link_id: {product_link_id}")
        print(f"üîç PROD DEBUG: product_image_url: {basic_info.get('image_url', 'None')}")
        logging.info(f"PROD DEBUG: Veri kaydediliyor - Link ID: {product_link_id}, Image URL var mƒ±: {bool(basic_info.get('image_url'))}")


        success = save_product_data(
            product_link_id=product_link_id,
            seller_name=basic_info.get('seller', 'Bilinmiyor'),
            product_title=basic_info.get('title', ''),
            price=basic_info.get('price', 0.0),
            comment_count=basic_info.get('comments', 0),
            question_count=basic_info.get('questions', 0), 
            rating=basic_info.get('rating', 0.0),
            sales_3day=basic_info.get('sales_3day'),  # ‚úÖ Bu yeterli
            seller_rating=basic_info.get('seller_rating', 0.0),
            scraped_by=scraped_by,
            product_image_url=basic_info.get('image_url')
            # daily_estimated_sales KALDIRDIK - zaten fonksiyonda hesaplanƒ±yor!
        )
        
        # Debug √ßƒ±ktƒ±larƒ± SONRA ekle
        if success:
            print(f"‚úÖ PROD DEBUG: save_product_data ba≈üarƒ±lƒ± - Image URL kaydedildi mi: {bool(basic_info.get('image_url'))}")
            logging.info(f"PROD DEBUG: Veri kaydetme ba≈üarƒ±lƒ± - Link ID: {product_link_id}")
            print(f"üîç DEBUG: √úr√ºn scraping ba≈üarƒ±lƒ±: {product_url}")
            return True
        else:
            print(f"‚ùå PROD DEBUG: save_product_data ba≈üarƒ±sƒ±z!")
            logging.error(f"PROD DEBUG: Veri kaydetme ba≈üarƒ±sƒ±z - Link ID: {product_link_id}")
            print(f"üîç DEBUG: Veri kaydetme hatasƒ±: {product_url}")
            return False
            
    except Exception as e:
        print(f"üîç DEBUG: √úr√ºn scraping exception: {product_url} - {str(e)}")
        return False

def update_scraping_status(is_running: bool = None, progress: int = None, 
                          total: int = None, current_item: str = None,
                          started_by: str = None, error: str = None,
                          success_count: int = None, failed_count: int = None):
    """Scraping durumunu g√ºnceller"""
    global scraping_status
    
    with scraping_lock:
        if is_running is not None:
            scraping_status['is_running'] = is_running
            if is_running:
                scraping_status['start_time'] = time.time()
                scraping_status['errors'] = []
                scraping_status['success_count'] = 0
                scraping_status['failed_count'] = 0
            
        if progress is not None:
            scraping_status['current_progress'] = progress
            
        if total is not None:
            scraping_status['total_items'] = total
            
        if current_item is not None:
            scraping_status['current_item'] = current_item
            
        if started_by is not None:
            scraping_status['started_by'] = started_by
            
        if error is not None:
            scraping_status['errors'].append(error)
            
        if success_count is not None:
            scraping_status['success_count'] = success_count
            
        if failed_count is not None:
            scraping_status['failed_count'] = failed_count

def get_scraping_status() -> Dict:
    """Mevcut scraping durumunu d√∂nd√ºr√ºr"""
    with scraping_lock:
        status = scraping_status.copy()
        if status['start_time']:
            status['elapsed_time'] = time.time() - status['start_time']
        else:
            status['elapsed_time'] = 0
        return status

def start_single_product_scraping(product_link_id: int, product_url: str, scraped_by: str):
    """
    Tek √ºr√ºn i√ßin arka planda scraping ba≈ülatƒ±r (yeni √ºr√ºn eklendiƒüinde)
    """
    def scrape_worker():
        try:
            success = scrape_single_product(product_link_id, product_url, scraped_by)
            if success:
                logging.info(f"Tek √ºr√ºn scraping tamamlandƒ±: {product_url}")
            else:
                logging.error(f"Tek √ºr√ºn scraping ba≈üarƒ±sƒ±z: {product_url}")
        except Exception as e:
            logging.error(f"Tek √ºr√ºn scraping worker hatasƒ±: {str(e)}")
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_manual_update(username: str) -> bool:
    """
    Manuel g√ºncelleme ba≈ülatƒ±r (Admin yetkisi gerekli)
    T√ºm aktif √ºr√ºnler i√ßin scraping yapar
    """
    def manual_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # T√ºm aktif √ºr√ºnleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Manuel g√ºncelleme ba≈ülatƒ±ldƒ±: {total_products} √ºr√ºn")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu g√ºncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"√úr√ºn {i+1}/{total_products}: {product_url[:50]}..."
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Scraping hatasƒ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Bekleme s√ºresi
                time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
            
            logging.info(f"Manuel g√ºncelleme tamamlandƒ±: {success_count}/{total_products} ba≈üarƒ±lƒ±")
            
        except Exception as e:
            error_msg = f"Manuel g√ºncelleme hatasƒ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # Eƒüer ba≈üka bir scraping devam ediyorsa ba≈ülatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, yeni i≈ülem ba≈ülatƒ±lmadƒ±")
        return False
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=manual_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def start_scheduled_update(username: str = "scheduler") -> bool:
    """
    Zamanlanmƒ±≈ü g√ºncelleme ba≈ülatƒ±r
    """
    def scheduled_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username)
            
            # T√ºm aktif √ºr√ºnleri al
            products = get_active_product_links()
            total_products = len(products)
            
            update_scraping_status(total=total_products, progress=0)
            
            logging.info(f"Otomatik g√ºncelleme ba≈ülatƒ±ldƒ±: {total_products} √ºr√ºn")
            
            success_count = 0
            failed_count = 0
            
            for i, product in enumerate(products):
                product_id = product['id']
                product_url = product['product_url']
                
                # Durumu g√ºncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"Otomatik: √úr√ºn {i+1}/{total_products}"
                )
                
                # Scraping yap
                success = scrape_single_product(product_id, product_url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Otomatik scraping hatasƒ±: {product_url}"
                    update_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Otomatik g√ºncellemede daha uzun bekleme
                time.sleep(random.uniform(REQUEST_DELAY_MIN + 2, REQUEST_DELAY_MAX + 3))
            
            logging.info(f"Otomatik g√ºncelleme tamamlandƒ±: {success_count}/{total_products} ba≈üarƒ±lƒ±")
            
        except Exception as e:
            error_msg = f"Otomatik g√ºncelleme hatasƒ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # Eƒüer ba≈üka bir scraping devam ediyorsa ba≈ülatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, otomatik i≈ülem atlandƒ±")
        return False
    
    # Arka planda √ßalƒ±≈ütƒ±r
    thread = threading.Thread(target=scheduled_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def is_scraping_running() -> bool:
    """Scraping i≈üleminin devam edip etmediƒüini kontrol eder"""
    return scraping_status['is_running']

def get_scraping_statistics() -> Dict:
    """
    Scraping istatistiklerini getirir
    """
    try:
        product_stats = get_product_statistics()
        scraping_stats = get_scraping_status()
        
        return {
            'product_stats': product_stats,
            'scraping_status': scraping_stats
        }
        
    except Exception as e:
        logging.error(f"Scraping istatistik hatasƒ±: {str(e)}")
        return {}

# Test fonksiyonu
def test_single_scraping(url: str):
    """Tek bir URL i√ßin test scraping"""
    logging.info(f"Test scraping ba≈ülatƒ±lƒ±yor: {url}")
    
    basic_info = scrape_product_basic_info(url)
    print("Temel bilgiler:", basic_info)
    
    sales_data = scrape_cart_sales_data(url)
    print("3 g√ºnl√ºk satƒ±≈ü:", sales_data)
    
    return basic_info, sales_data