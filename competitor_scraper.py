"""
Rakip Fiyat Takip ModÃ¼lÃ¼ - Web Scraping
Trendyol sayfalarÄ±ndan Ã¼rÃ¼n bilgilerini Ã§eker
YENÄ°: Slot 0 (NeÅŸeliÃ‡iÃ§ekler) desteÄŸi eklendi
DÃœZELTME: TÃ¼m parametre uyumsuzluklarÄ± giderildi
"""

import requests
from bs4 import BeautifulSoup
import time
import random
import logging
import threading
import re
from typing import Dict, Optional, List
from competitor_tracking import (
    save_scraped_price, 
    get_all_active_links,
    get_links_by_barcode
)

# Scraping ayarlarÄ±
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
]

REQUEST_DELAY_MIN = 2  # Minimum bekleme sÃ¼resi (saniye)
REQUEST_DELAY_MAX = 5  # Maximum bekleme sÃ¼resi (saniye)
REQUEST_TIMEOUT = 15   # Ä°stek timeout sÃ¼resi (saniye)

# YENÄ°: Slot 0 iÃ§in Ã¶zel ayarlar
NESELICICEKLER_DELAY_MIN = 3  # NeÅŸeliÃ‡iÃ§ekler iÃ§in daha uzun bekleme
NESELICICEKLER_DELAY_MAX = 7

# Global scraping durumu
scraping_status = {
    'is_running': False,
    'current_progress': 0,
    'total_items': 0,
    'current_item': '',
    'started_by': '',
    'start_time': None,
    'errors': [],
    'include_slot_0': False,  # YENÄ°: Slot 0 dahil mi?
    'slot_0_processed': 0,    # YENÄ°: Slot 0 iÅŸlem sayÄ±sÄ±
    'competitor_processed': 0  # YENÄ°: Rakip slot iÅŸlem sayÄ±sÄ±
}

scraping_lock = threading.Lock()

def get_random_headers() -> Dict[str, str]:
    """Rastgele User-Agent ile header oluÅŸturur"""
    return {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
    }

def scrape_trendyol_product(url: str, slot_number: int = 1) -> Optional[Dict[str, str]]:
    """
    Trendyol Ã¼rÃ¼n sayfasÄ±ndan bilgileri Ã§eker
    YENÄ°: slot_number parametresi eklendi (slot 0 iÃ§in Ã¶zel iÅŸlemler)
    Returns: {'product_name': str, 'price': float, 'seller_name': str} or None
    """
    try:
        headers = get_random_headers()
        
        # YENÄ°: Slot 0 iÃ§in daha uzun bekleme
        if slot_number == 0:
            delay = random.uniform(NESELICICEKLER_DELAY_MIN, NESELICICEKLER_DELAY_MAX)
            logging.info(f"NeÅŸeliÃ‡iÃ§ekler slot scraping (daha uzun bekleme): {delay:.1f}s")
        else:
            delay = random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX)
        
        time.sleep(delay)
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        # DEBUG KODLARI BURAYA EKLE:
        print(f"DEBUG: HTML iÃ§eriÄŸi uzunluÄŸu: {len(response.content)}")
        print(f"DEBUG: Ä°lk 500 karakter:")
        print(response.text[:500])
        print(f"DEBUG: 'price' kelimesi var mÄ±: {'price' in response.text.lower()}")
        soup = BeautifulSoup(response.content, 'lxml')
        
        # ÃœrÃ¼n adÄ±nÄ± Ã§ek - TAM BAÅLIK
        product_name = None
        name_selectors = [
            'h1[data-testid="product-title"]',  # Sizin bulduÄŸunuz - tam baÅŸlÄ±k
            'h1.product-title',
            'h1.pr-new-br',  # TÃ¼m h1, sadece span deÄŸil
            'h1',  # Genel h1
            '.product-name h1',
            '.pr-new-br',
            'h1[data-testid="product-name"]',
            '.product-title'
        ]
        
        for selector in name_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                # HTML tag'larÄ±nÄ± temizle ve tam metni al
                product_name = element.get_text(separator=' ', strip=True)
                
                # YENÄ°: Slot 0 iÃ§in Ã¶zel loglama
                if slot_number == 0:
                    logging.info(f"NeÅŸeliÃ‡iÃ§ekler Ã¼rÃ¼n adÄ± bulundu - Selector: {selector}, DeÄŸer: {product_name[:100]}...")
                else:
                    logging.info(f"ÃœrÃ¼n adÄ± bulundu - Selector: {selector}, DeÄŸer: {product_name[:100]}...")
                break
        
        # FiyatÄ± Ã§ek - GÃœNCELLENMÄ°Å: product_scraper.py ile aynÄ± mantÄ±k
        price = None
        
        print(f"ğŸ” COMPETITOR DEBUG: Price selector aramasÄ± baÅŸlÄ±yor... (Slot {slot_number})")
        
        price_selectors = [
            # YENÄ°: Ä°ndirimli fiyat Ã¶nceliÄŸi (product_scraper.py ile uyumlu)
            '.price-view-discounted',            # Ä°ndirimli fiyat (611 TL)
            '[data-testid="price"] .price-view-discounted', # Daha spesifik indirimli
            '.price-view span:last-child',       # Price-view iÃ§indeki son span
            
            # YENÄ°: Kampanya fiyatlarÄ±
            '.campaign-price .new-price',        # KampanyalÄ± fiyat iÃ§in
            '.campaign-price-content .new-price', # Spesifik kampanya fiyatÄ±
            'p.new-price',                       # p tag ile new-price
            '.campaign-price p.new-price',       # Campaign iÃ§i new-price
            
            # ESKÄ°: Mevcut selector'lar (korundu)
            '.prc-dsc',
            '.prc-slg',
            '.product-price .prc-dsc',
            
            # YENÄ°: Ek selector'lar
            '[data-testid="price-current-price"]', # Test ID ile
            '.price-current',                    # Mevcut fiyat
            'span[class*="price"]',              # Price iÃ§eren span
            '.prc-cntr .prc-dsc',               # Price container iÃ§i
            '.price-container span',             # Price container span
            'div[class*="price"] span',          # Price div iÃ§i span
            '.product-price span:last-child',    # Son span
            'span[data-testid*="price"]',        # Price test ID'li span
            
            # YENÄ°: Genel selector'lar
            '*[class*="price"]:not(:empty)',     # Price iÃ§eren boÅŸ olmayan elementler
            '*[class*="prc"]:not(:empty)',       # Prc iÃ§eren boÅŸ olmayan elementler
            
            # ESKÄ°: Eski container (korundu)
            '.product-price-container .prc-dsc'
        ]
        
        price_found = False
        for i, selector in enumerate(price_selectors):
            print(f"ğŸ” COMPETITOR DEBUG: Price selector {i+1}/{len(price_selectors)} deneniyor: {selector} (Slot {slot_number})")
            
            try:
                element = soup.select_one(selector)
                if element:
                    price_text = element.get_text(strip=True)
                    print(f"âœ… COMPETITOR DEBUG: Element bulundu! Ham text: '{price_text}' (Slot {slot_number})")
                    
                    # Text boÅŸsa alternative attribute'larÄ± dene
                    if not price_text:
                        alternative_attributes = ['textContent', 'innerText', 'value', 'data-price', 'title']
                        for attr in alternative_attributes:
                            try:
                                attr_value = element.get(attr)
                                if attr_value and attr_value.strip():
                                    price_text = attr_value.strip()
                                    print(f"ğŸ” COMPETITOR DEBUG: Text '{attr}' attribute'unda bulundu: '{price_text}' (Slot {slot_number})")
                                    break
                            except:
                                continue
                    
                    if not price_text:
                        print(f"âš ï¸ COMPETITOR DEBUG: Element boÅŸ text dÃ¶ndÃ¼rdÃ¼ (Slot {slot_number})")
                        continue
                    
                    # GeliÅŸmiÅŸ fiyat temizleme - product_scraper.py ile aynÄ± mantÄ±k
                    if price_text:
                        print(f"ğŸ”§ COMPETITOR DEBUG: Fiyat temizleme baÅŸlÄ±yor... (Slot {slot_number})")
                        
                        # Sadece rakam, nokta, virgÃ¼l ve boÅŸluk karakterlerini al
                        price_clean = re.sub(r'[^\d\s,.]', '', price_text)
                        print(f"ğŸ”§ COMPETITOR DEBUG: Ä°lk temizlik sonrasÄ±: '{price_clean}' (Slot {slot_number})")
                        
                        original_clean = price_clean
                        
                        # NoktayÄ± binlik ayracÄ± olarak kabul et, virgÃ¼lÃ¼ ondalÄ±k ayracÄ± olarak
                        if ',' in price_clean and '.' in price_clean:
                            # Her ikisi varsa: nokta binlik, virgÃ¼l ondalÄ±k
                            print(f"ğŸ”§ COMPETITOR DEBUG: Hem nokta hem virgÃ¼l var - nokta binlik, virgÃ¼l ondalÄ±k kabul ediliyor (Slot {slot_number})")
                            price_clean = price_clean.replace('.', '').replace(',', '.')
                            print(f"ğŸ”§ COMPETITOR DEBUG: DÃ¶nÃ¼ÅŸÃ¼m sonrasÄ±: '{price_clean}' (Slot {slot_number})")
                        elif '.' in price_clean:
                            # Sadece nokta varsa: eÄŸer 3 haneli ise binlik, deÄŸilse ondalÄ±k
                            parts = price_clean.split('.')
                            print(f"ğŸ”§ COMPETITOR DEBUG: Sadece nokta var, parÃ§alar: {parts} (Slot {slot_number})")
                            if len(parts) == 2 and len(parts[1]) == 3:
                                # 3 haneli son kÄ±sÄ±m = binlik ayracÄ±
                                print(f"ğŸ”§ COMPETITOR DEBUG: Son kÄ±sÄ±m 3 haneli ({parts[1]}) - binlik ayracÄ± olarak kabul ediliyor (Slot {slot_number})")
                                price_clean = price_clean.replace('.', '')
                                print(f"ğŸ”§ COMPETITOR DEBUG: Binlik ayracÄ± kaldÄ±rÄ±ldÄ±: '{price_clean}' (Slot {slot_number})")
                            else:
                                print(f"ğŸ”§ COMPETITOR DEBUG: Son kÄ±sÄ±m {len(parts[1]) if len(parts) > 1 else 0} haneli - ondalÄ±k ayracÄ± olarak bÄ±rakÄ±lÄ±yor (Slot {slot_number})")
                        elif ',' in price_clean:
                            # Sadece virgÃ¼l varsa: ondalÄ±k ayracÄ± olarak kabul et
                            print(f"ğŸ”§ COMPETITOR DEBUG: Sadece virgÃ¼l var - ondalÄ±k ayracÄ± olarak kabul ediliyor (Slot {slot_number})")
                            price_clean = price_clean.replace(',', '.')
                            print(f"ğŸ”§ COMPETITOR DEBUG: VirgÃ¼l nokta ile deÄŸiÅŸtirildi: '{price_clean}' (Slot {slot_number})")
                        else:
                            print(f"ğŸ”§ COMPETITOR DEBUG: AyraÃ§ yok, olduÄŸu gibi bÄ±rakÄ±lÄ±yor (Slot {slot_number})")
                        
                        # BoÅŸluklarÄ± temizle
                        price_clean = price_clean.replace(' ', '')
                        print(f"ğŸ”§ COMPETITOR DEBUG: BoÅŸluklar temizlendi: '{price_clean}' (Slot {slot_number})")
                        
                        if price_clean:
                            try:
                                parsed_price = float(price_clean)
                                
                                # MantÄ±klÄ± fiyat aralÄ±ÄŸÄ±nda mÄ± kontrol et (YENÄ°)
                                if 10 <= parsed_price <= 1000000:
                                    price = parsed_price
                                    print(f"âœ… COMPETITOR DEBUG: FÄ°YAT BAÅARIYLA PARSE EDÄ°LDÄ°! (Slot {slot_number})")
                                    print(f"âœ… COMPETITOR DEBUG: KullanÄ±lan selector: '{selector}' (Slot {slot_number})")
                                    print(f"âœ… COMPETITOR DEBUG: Ham text: '{price_text}' (Slot {slot_number})")
                                    print(f"âœ… COMPETITOR DEBUG: TemizlenmiÅŸ text: '{original_clean}' -> '{price_clean}' (Slot {slot_number})")
                                    print(f"âœ… COMPETITOR DEBUG: Final fiyat: {parsed_price} (Slot {slot_number})")
                                    
                                    # YENÄ°: Slot 0 iÃ§in Ã¶zel loglama
                                    if slot_number == 0:
                                        logging.info(f"NeÅŸeliÃ‡iÃ§ekler fiyat bulundu: {parsed_price}â‚º")
                                    else:
                                        logging.info(f"Fiyat bulundu: {parsed_price}â‚º")
                                    
                                    price_found = True
                                    break
                                else:
                                    print(f"âš ï¸ COMPETITOR DEBUG: Fiyat mantÄ±ksÄ±z aralÄ±kta ({parsed_price}), atlanÄ±yor (Slot {slot_number})")
                                    continue
                                    
                            except ValueError as ve:
                                print(f"âŒ COMPETITOR DEBUG: Float dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: {str(ve)} (Slot {slot_number})")
                                print(f"âŒ COMPETITOR DEBUG: Text: '{price_text}' -> Clean: '{price_clean}' (Slot {slot_number})")
                                continue
                
                else:
                    print(f"âŒ COMPETITOR DEBUG: Selector eleman bulamadÄ± (Slot {slot_number})")
                    
            except Exception as e:
                print(f"âŒ COMPETITOR DEBUG: Selector hatasÄ±: {str(e)} (Slot {slot_number})")
                continue
        
        if not price_found:
            print(f"âŒ COMPETITOR DEBUG: HÄ°Ã‡BÄ°R SELECTOR'DAN FÄ°YAT ALINAMADI! (Slot {slot_number})")
            print(f"âŒ COMPETITOR DEBUG: Toplam {len(price_selectors)} selector denendi (Slot {slot_number})")
            print(f"âŒ COMPETITOR DEBUG: Final result price: {price} (Slot {slot_number})")
        else:
            print(f"ğŸ‰ COMPETITOR DEBUG: FÄ°YAT BAÅARIYLA BELÄ°RLENDÄ°: {price} (Slot {slot_number})")
        
        # SatÄ±cÄ± adÄ±nÄ± Ã§ek - Debug sonuÃ§larÄ±na gÃ¶re gÃ¼ncellendi
        seller_name = None
        
        # Ã–ncelikle doÄŸru selector'Ä± dene
        seller_selectors = [
            '.product-description-market-place',  # Debug'da bulduÄŸumuz doÄŸru selector!
            'span.product-description-market-place',  # Daha spesifik
            '.merchant-name',  # Yedek
            'div[class*="merchant-name"]',  
            '[class*="merchant-name"]',  
            '.seller-name', 
            '.product-merchant a',
            '.pdp-merchant-info a',
            '[data-testid="merchant-name"]',
            '.merchant-info .merchant-name'
        ]
        
        for selector in seller_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                seller_name = element.get_text(strip=True)
                
                # YENÄ°: Slot 0 iÃ§in Ã¶zel loglama
                if slot_number == 0:
                    logging.info(f"NeÅŸeliÃ‡iÃ§ekler satÄ±cÄ± bulundu - Selector: {selector}, DeÄŸer: {seller_name}")
                else:
                    logging.info(f"SatÄ±cÄ± bulundu - Selector: {selector}, DeÄŸer: {seller_name}")
                break
        
        # Dinamik class arama (yedek)
        if not seller_name:
            merchant_divs = soup.find_all('div', class_=lambda x: x and 'merchant-name' in str(x))
            if merchant_divs:
                seller_name = merchant_divs[0].get_text(strip=True)
                
                # YENÄ°: Slot 0 iÃ§in Ã¶zel loglama
                if slot_number == 0:
                    logging.info(f"NeÅŸeliÃ‡iÃ§ekler dinamik class ile satÄ±cÄ± bulundu: {seller_name}")
                else:
                    logging.info(f"Dinamik class ile satÄ±cÄ± bulundu: {seller_name}")
        
        # YENÄ°: Slot 0 iÃ§in NeÅŸeliÃ‡iÃ§ekler kontrolÃ¼
        if slot_number == 0:
            # NeÅŸeliÃ‡iÃ§ekler text'ini direkt ara
            neseli_spans = soup.find_all('span', string=lambda text: text and 'NeÅŸeliÃ‡iÃ§ekler' in text)
            if neseli_spans:
                seller_name = neseli_spans[0].get_text(strip=True)
                logging.info(f"NeÅŸeliÃ‡iÃ§ekler direct text search ile bulundu: {seller_name}")
            elif not seller_name:
                # Slot 0 ise ve satÄ±cÄ± bulunamazsa NeÅŸeliÃ‡iÃ§ekler olarak varsay
                seller_name = "NeÅŸeliÃ‡iÃ§ekler"
                logging.info(f"Slot 0 iÃ§in varsayÄ±lan satÄ±cÄ±: {seller_name}")
        else:
            # Rakip Ã¼rÃ¼nler iÃ§in CenNetHome kontrolÃ¼
            cennet_spans = soup.find_all('span', string=lambda text: text and 'CenNetHome' in text)
            if cennet_spans:
                seller_name = cennet_spans[0].get_text(strip=True)
                logging.info(f"Direct text search ile satÄ±cÄ± bulundu: {seller_name}")
        
        # EÄŸer satÄ±cÄ± hala bulunamazsa
        if not seller_name:
            if slot_number == 0:
                logging.warning(f"NeÅŸeliÃ‡iÃ§ekler satÄ±cÄ± bulunamadÄ± - URL: {url}")
                seller_name = "NeÅŸeliÃ‡iÃ§ekler"  # VarsayÄ±lan
            else:
                logging.warning(f"SatÄ±cÄ± bulunamadÄ± - URL: {url}")
                seller_name = "Bilinmiyor"
        
        # SonuÃ§larÄ± kontrol et
        if product_name and price is not None:
            return {
                'product_name': product_name[:200],  # Uzunluk sÄ±nÄ±rÄ±
                'price': price,
                'seller_name': seller_name[:100] if seller_name else ("NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else "Bilinmiyor")
            }
        else:
            slot_info = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Slot {slot_number}"
            logging.warning(f"Eksik veri - {slot_info} - URL: {url}, Name: {product_name}, Price: {price}, Seller: {seller_name}")
            return None
            
    except requests.exceptions.RequestException as e:
        slot_info = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Slot {slot_number}"
        logging.error(f"Request hatasÄ± - {slot_info} - {url}: {str(e)}")
        return None
    except Exception as e:
        slot_info = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Slot {slot_number}"
        logging.error(f"Scraping hatasÄ± - {slot_info} - {url}: {str(e)}")
        return None

def update_scraping_status(is_running: bool = None, progress: int = None, 
                          total: int = None, current_item: str = None,
                          started_by: str = None, error: str = None,
                          include_slot_0: bool = None, 
                          slot_0_processed: int = None,
                          competitor_processed: int = None):
    """
    Scraping durumunu gÃ¼nceller
    YENÄ°: Slot 0 istatistikleri eklendi
    """
    global scraping_status
    
    with scraping_lock:
        if is_running is not None:
            scraping_status['is_running'] = is_running
            if is_running:
                scraping_status['start_time'] = time.time()
                scraping_status['errors'] = []
                scraping_status['slot_0_processed'] = 0
                scraping_status['competitor_processed'] = 0
            
        if progress is not None:
            scraping_status['current_progress'] = progress
            
        if total is not None:
            scraping_status['total_items'] = total
            
        if current_item is not None:
            scraping_status['current_item'] = current_item
            
        if started_by is not None:
            scraping_status['started_by'] = started_by
            
        if error is not None:
            scraping_status['errors'].append(error)
            
        if include_slot_0 is not None:
            scraping_status['include_slot_0'] = include_slot_0
            
        if slot_0_processed is not None:
            scraping_status['slot_0_processed'] = slot_0_processed
            
        if competitor_processed is not None:
            scraping_status['competitor_processed'] = competitor_processed

def get_update_status() -> Dict:
    """
    Mevcut scraping durumunu dÃ¶ndÃ¼rÃ¼r
    YENÄ°: Slot 0 istatistikleri dahil
    """
    with scraping_lock:
        status = scraping_status.copy()
        if status['start_time']:
            status['elapsed_time'] = time.time() - status['start_time']
        else:
            status['elapsed_time'] = 0
        return status

def scrape_single_link(barcode: str, slot_number: int, url: str, scraped_by: str) -> bool:
    """
    Tek bir link iÃ§in scraping yapar
    YENÄ°: slot_number 0 desteÄŸi - DÃœZELTME: scrape_source parametresi kaldÄ±rÄ±ldÄ±
    """
    try:
        slot_info = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Rakip Slot {slot_number}"
        logging.info(f"Scraping baÅŸlatÄ±lÄ±yor: {barcode} - {slot_info} - {url}")
        
        product_data = scrape_trendyol_product(url, slot_number)
        
        if product_data:
            success = save_scraped_price(
                barcode=barcode,
                competitor_url=url,
                slot_number=slot_number,
                product_name=product_data['product_name'],
                price=product_data['price'],
                seller_name=product_data['seller_name'],
                scraped_by=scraped_by
                # scrape_source kaldÄ±rÄ±ldÄ±
            )
            
            if success:
                logging.info(f"Scraping baÅŸarÄ±lÄ±: {barcode} - {slot_info} - {product_data['price']}â‚º")
                return True
            else:
                logging.error(f"Veri kaydetme hatasÄ±: {barcode} - {slot_info} - {url}")
                return False
        else:
            logging.warning(f"Scraping baÅŸarÄ±sÄ±z: {barcode} - {slot_info} - {url}")
            return False
            
    except Exception as e:
        slot_info = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Rakip Slot {slot_number}"
        logging.error(f"Scraping exception: {barcode} - {slot_info} - {url} - {str(e)}")
        return False

def start_scraping_for_new_links(barcode: str, links: List[str], scraped_by: str):
    """
    Yeni kaydedilen linkler iÃ§in scraping baÅŸlatÄ±r (ESKÄ° FONKSÄ°YON - Sadece slot 1-5)
    Arka planda Ã§alÄ±ÅŸÄ±r
    """
    def scrape_worker():
        try:
            active_links = get_links_by_barcode(barcode, include_slot_0=False)
            link_dict = {link['slot_number']: link['url'] for link in active_links}
            
            for slot_number, url in enumerate(links, 1):
                if url.strip() and slot_number in link_dict:
                    if link_dict[slot_number] == url.strip():
                        scrape_single_link(barcode, slot_number, url.strip(), scraped_by)
                        
        except Exception as e:
            logging.error(f"Yeni link scraping hatasÄ±: {str(e)}")
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_scraping_for_new_links_by_slots(barcode: str, slot_links: Dict[int, str], scraped_by: str):
    """
    YENÄ°: Slot numaralarÄ± ile yeni kaydedilen linkler iÃ§in scraping baÅŸlatÄ±r
    slot_links: {slot_number: url}
    """
    def scrape_worker():
        try:
            for slot_number, url in slot_links.items():
                if url and url.strip():
                    scrape_single_link(barcode, slot_number, url.strip(), scraped_by)
                    
                    # Slot 0 iÃ§in daha uzun bekleme
                    if slot_number == 0:
                        time.sleep(random.uniform(NESELICICEKLER_DELAY_MIN, NESELICICEKLER_DELAY_MAX))
                    else:
                        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
                        
        except Exception as e:
            logging.error(f"Yeni slot link scraping hatasÄ±: {str(e)}")
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_manual_update(username: str):
    """
    Manuel gÃ¼ncelleme baÅŸlatÄ±r - ESKÄ° FONKSÄ°YON (Sadece slot 1-5)
    TÃ¼m aktif linkler iÃ§in scraping yapar
    """
    return start_manual_update_with_slot_0(username, include_slot_0=False)

def start_manual_update_with_slot_0(username: str, include_slot_0: bool = True):
    """
    YENÄ°: Manuel gÃ¼ncelleme baÅŸlatÄ±r (Slot 0 dahil edilebilir)
    """
    def manual_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username, include_slot_0=include_slot_0)
            
            # TÃ¼m aktif linkleri al
            all_links = get_all_active_links(include_slot_0=include_slot_0)
            total_links = len(all_links)
            
            update_scraping_status(total=total_links, progress=0)
            
            slot_info = "Slot 0-5" if include_slot_0 else "Slot 1-5"
            logging.info(f"Manuel gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_links} link ({slot_info})")
            
            success_count = 0
            slot_0_count = 0
            competitor_count = 0
            
            for i, link_data in enumerate(all_links):
                barcode = link_data['barcode']
                slot_number = link_data['slot_number']
                url = link_data['url']
                
                # Durumu gÃ¼ncelle
                slot_display = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Rakip Slot {slot_number}"
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"{barcode} - {slot_display}"
                )
                
                # Scraping yap - DÃœZELTME: 4 parametre
                success = scrape_single_link(barcode, slot_number, url, username)
                
                if success:
                    success_count += 1
                    if slot_number == 0:
                        slot_0_count += 1
                        update_scraping_status(slot_0_processed=slot_0_count)
                    else:
                        competitor_count += 1
                        update_scraping_status(competitor_processed=competitor_count)
                else:
                    error_msg = f"Scraping hatasÄ±: {barcode} - {slot_display}"
                    update_scraping_status(error=error_msg)
                
                # Slot 0 iÃ§in daha uzun bekleme
                if slot_number == 0:
                    time.sleep(random.uniform(NESELICICEKLER_DELAY_MIN, NESELICICEKLER_DELAY_MAX))
                else:
                    time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
            
            stats_info = f"{success_count}/{total_links} baÅŸarÄ±lÄ±"
            if include_slot_0:
                stats_info += f" (NeÅŸeliÃ‡iÃ§ekler: {slot_0_count}, Rakipler: {competitor_count})"
            
            logging.info(f"Manuel gÃ¼ncelleme tamamlandÄ±: {stats_info}")
            
        except Exception as e:
            error_msg = f"Manuel gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, yeni iÅŸlem baÅŸlatÄ±lmadÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=manual_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def start_scheduled_update(username: str = "scheduler", include_slot_0: bool = True):
    """
    ZamanlanmÄ±ÅŸ gÃ¼ncelleme baÅŸlatÄ±r
    YENÄ°: include_slot_0 parametresi eklendi
    """
    def scheduled_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username, include_slot_0=include_slot_0)
            
            # TÃ¼m aktif linkleri al
            all_links = get_all_active_links(include_slot_0=include_slot_0)
            total_links = len(all_links)
            
            update_scraping_status(total=total_links, progress=0)
            
            slot_info = "Slot 0-5" if include_slot_0 else "Slot 1-5"
            logging.info(f"Otomatik gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_links} link ({slot_info})")
            
            success_count = 0
            slot_0_count = 0
            competitor_count = 0
            
            for i, link_data in enumerate(all_links):
                barcode = link_data['barcode']
                slot_number = link_data['slot_number']
                url = link_data['url']
                
                # Durumu gÃ¼ncelle
                slot_display = "NeÅŸeliÃ‡iÃ§ekler" if slot_number == 0 else f"Rakip Slot {slot_number}"
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"{barcode} - {slot_display}"
                )
                
                # Scraping yap - DÃœZELTME: 4 parametre
                success = scrape_single_link(barcode, slot_number, url, username)
                
                if success:
                    success_count += 1
                    if slot_number == 0:
                        slot_0_count += 1
                        update_scraping_status(slot_0_processed=slot_0_count)
                    else:
                        competitor_count += 1
                        update_scraping_status(competitor_processed=competitor_count)
                else:
                    error_msg = f"Otomatik scraping hatasÄ±: {barcode} - {slot_display}"
                    update_scraping_status(error=error_msg)
                
                # Otomatik gÃ¼ncellemede daha uzun bekleme - Slot 0 iÃ§in extra uzun
                if slot_number == 0:
                    time.sleep(random.uniform(NESELICICEKLER_DELAY_MIN + 2, NESELICICEKLER_DELAY_MAX + 3))
                else:
                    time.sleep(random.uniform(REQUEST_DELAY_MIN + 1, REQUEST_DELAY_MAX + 2))
            
            stats_info = f"{success_count}/{total_links} baÅŸarÄ±lÄ±"
            if include_slot_0:
                stats_info += f" (NeÅŸeliÃ‡iÃ§ekler: {slot_0_count}, Rakipler: {competitor_count})"
            
            logging.info(f"Otomatik gÃ¼ncelleme tamamlandÄ±: {stats_info}")
            
        except Exception as e:
            error_msg = f"Otomatik gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, otomatik iÅŸlem atlandÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scheduled_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def is_scraping_running() -> bool:
    """Scraping iÅŸleminin devam edip etmediÄŸini kontrol eder"""
    return scraping_status['is_running']

# YENÄ° FONKSÄ°YONLAR: NeÅŸeliÃ‡iÃ§ekler Ã¶zel iÅŸlemleri

def start_neselicicekler_only_update(username: str):
    """
    Sadece NeÅŸeliÃ‡iÃ§ekler (slot 0) linklerini gÃ¼nceller
    """
    def neseli_update_worker():
        try:
            update_scraping_status(is_running=True, started_by=username, include_slot_0=True)
            
            # Sadece slot 0 linklerini al
            from competitor_tracking import get_all_active_links_by_slot
            neseli_links = get_all_active_links_by_slot(0)
            total_links = len(neseli_links)
            
            update_scraping_status(total=total_links, progress=0)
            
            logging.info(f"NeÅŸeliÃ‡iÃ§ekler gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_links} link")
            
            success_count = 0
            
            for i, link_data in enumerate(neseli_links):
                barcode = link_data['barcode']
                url = link_data['url']
                
                # Durumu gÃ¼ncelle
                update_scraping_status(
                    progress=i + 1,
                    current_item=f"{barcode} - NeÅŸeliÃ‡iÃ§ekler"
                )
                
                # Scraping yap - DÃœZELTME: 4 parametre
                success = scrape_single_link(barcode, 0, url, username)
                
                if success:
                    success_count += 1
                    update_scraping_status(slot_0_processed=success_count)
                else:
                    error_msg = f"NeÅŸeliÃ‡iÃ§ekler scraping hatasÄ±: {barcode}"
                    update_scraping_status(error=error_msg)
                
                # Uzun bekleme
                time.sleep(random.uniform(NESELICICEKLER_DELAY_MIN, NESELICICEKLER_DELAY_MAX))
            
            logging.info(f"NeÅŸeliÃ‡iÃ§ekler gÃ¼ncelleme tamamlandÄ±: {success_count}/{total_links} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            error_msg = f"NeÅŸeliÃ‡iÃ§ekler gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_scraping_status(error=error_msg)
        finally:
            update_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if scraping_status['is_running']:
        logging.warning("Scraping zaten devam ediyor, NeÅŸeliÃ‡iÃ§ekler iÅŸlem baÅŸlatÄ±lmadÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=neseli_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def get_scraping_statistics() -> Dict:
    """
    Scraping istatistiklerini getirir
    """
    try:
        from competitor_tracking import get_neselicicekler_price_stats, get_total_prices_count
        
        stats = {
            'neselicicekler': get_neselicicekler_price_stats(),
            'competitor_total': get_total_prices_count(include_slot_0=False),
            'all_total': get_total_prices_count(include_slot_0=True),
            'scraping_status': get_update_status()
        }
        
        return stats
        
    except Exception as e:
        logging.error(f"Ä°statistik getirme hatasÄ±: {str(e)}")
        return {}