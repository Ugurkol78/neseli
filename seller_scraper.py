"""
SatÄ±cÄ± Ä°zleme ve Analiz ModÃ¼lÃ¼ - Web Scraping (Selenium)
Product scraper'dan aynÄ± Selenium yapÄ±sÄ±nÄ± kullanÄ±r
Production/Local uyumlu Chrome driver setup
"""

import requests
from bs4 import BeautifulSoup
import time
import random
import logging
import threading
from typing import Dict, Optional, List
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

from seller_tracking import (
    get_active_seller_links, save_seller_data, 
    get_seller_statistics, parse_follower_count, parse_store_age
)

# Scraping ayarlarÄ± (Product scraper ile aynÄ±)
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

REQUEST_DELAY_MIN = 5  # Seller iÃ§in daha uzun bekleme
REQUEST_DELAY_MAX = 10
REQUEST_TIMEOUT = 30

# Global scraping durumu
seller_scraping_status = {
    'is_running': False,
    'current_progress': 0,
    'total_items': 0,
    'current_item': '',
    'started_by': '',
    'start_time': None,
    'errors': [],
    'success_count': 0,
    'failed_count': 0
}

seller_scraping_lock = threading.Lock()

def setup_chrome_driver() -> webdriver.Chrome:
    """
    Chrome WebDriver'Ä± headless modda kuruluma hazÄ±rlar
    Production ve Local iÃ§in uyumlu
    """
    print(f"ğŸ” SELLER DEBUG: Chrome driver kuruluyor...")
    
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument(f'--user-agent={random.choice(USER_AGENTS)}')
    
    print(f"ğŸ” SELLER DEBUG: Chrome options ayarlandÄ± (headless mode)")
    
    try:
        # Ã–NCE Production path'i dene (VPS iÃ§in)
        service = Service('/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"âœ… SELLER DEBUG: Chrome driver baÅŸarÄ±yla kuruldu (Production path)")
        return driver
    except Exception as prod_error:
        print(f"âš ï¸ SELLER DEBUG: Production path baÅŸarÄ±sÄ±z: {str(prod_error)}")
        
        # Local development iÃ§in WebDriverManager dene
        try:
            print(f"ğŸ” SELLER DEBUG: WebDriverManager deneniyor (Local)...")
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            print(f"âœ… SELLER DEBUG: Chrome driver baÅŸarÄ±yla kuruldu (WebDriverManager)")
            return driver
        except Exception as local_error:
            print(f"âŒ SELLER DEBUG: WebDriverManager da baÅŸarÄ±sÄ±z: {str(local_error)}")
            logging.error(f"SELLER DEBUG: Chrome driver hatasÄ±: Production: {str(prod_error)}, Local: {str(local_error)}")
            raise local_error

# GeÃ§ici: Requests ile fallback scraper
def scrape_with_requests_fallback(url: str) -> Optional[Dict[str, any]]:
    """
    Chrome yokken geÃ§ici requests Ã§Ã¶zÃ¼mÃ¼
    """
    try:
        headers = {
            'User-Agent': random.choice(USER_AGENTS),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive'
        }
        
        time.sleep(random.uniform(3, 6))
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        
        print(f"ğŸ” FALLBACK: Requests ile sayfa Ã§ekildi: {len(response.text)} karakter")
        
        # Basit veri Ã§ekme
        result = {
            'seller_name': None,
            'seller_score': None,
            'product_count': None,
            'follower_count': None
        }
        
        # Title'dan satÄ±cÄ± adÄ± Ã§Ä±karma
        title = soup.title.string if soup.title else ""
        if title:
            # "SatÄ±cÄ± AdÄ± - Trendyol" formatÄ±ndan Ã§Ä±kar
            if " - Trendyol" in title:
                result['seller_name'] = title.replace(" - Trendyol", "").strip()
        
        print(f"ğŸ” FALLBACK: SonuÃ§: {result}")
        return result
        
    except Exception as e:
        print(f"âŒ FALLBACK: Requests hatasÄ±: {str(e)}")
        return None

def scrape_all_products_page_selenium(url: str) -> Optional[Dict[str, any]]:
    """
    Selenium ile TÃ¼m ÃœrÃ¼nler SayfasÄ±'ndan veri Ã§eker
    Chrome yoksa requests fallback kullanÄ±r
    Returns: {'seller_name': str, 'seller_score': float, 'product_count': int, 'follower_count': int}
    """
    # Ã–nce Chrome driver dene
    try:
        driver = setup_chrome_driver()
    except Exception as e:
        print(f"âŒ SELLER DEBUG: Selenium baÅŸarÄ±sÄ±z, requests fallback kullanÄ±lÄ±yor")
        return scrape_with_requests_fallback(url)
    
    try:
        print(f"ğŸ” SELLER DEBUG: TÃ¼m Ã¼rÃ¼nler sayfasÄ± Ã§ekiliyor: {url}")
        driver.get(url)
        
        # Sayfa yÃ¼klenene kadar bekle
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScript'in tam yÃ¼klenmesi iÃ§in bekleme
        time.sleep(random.uniform(3, 6))
        
        # SayfayÄ± scroll et (lazy loading iÃ§in)
        driver.execute_script("window.scrollTo(0, 800);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        result = {
            'seller_name': None,
            'seller_score': None,
            'product_count': None,
            'follower_count': None
        }
        
        # Bot tespit kontrolÃ¼
        page_title = driver.title
        if "robot" in page_title.lower() or "captcha" in page_title.lower():
            print("ğŸ¤– SELLER DEBUG: Bot tespit sayfasÄ± algÄ±landÄ±!")
            return None
        
        print(f"ğŸ” SELLER DEBUG: Sayfa baÅŸlÄ±ÄŸÄ±: {page_title}")
        
        # SatÄ±cÄ± AdÄ± - GeliÅŸmiÅŸ selector'lar
        seller_name_selectors = [
            'h1.seller-store__name.seller-info__name.ss-header-seller',
            'h1.seller-store__name',
            'h1[class*="seller-store__name"]',
            'h1[class*="seller-info__name"]',
            '.seller-store__name',
            '.seller-info__name',
            'h1[style*="color:#FFFFFF"]',
            '.seller-name',
            '.store-name',
            '[data-testid="seller-name"]',
            '.merchant-name',
            'h1'  # Fallback
        ]
        
        for selector in seller_name_selectors:
            try:
                element = driver.find_element(By.CSS_SELECTOR, selector)
                if element and element.text.strip():
                    result['seller_name'] = element.text.strip()
                    print(f"âœ… SELLER DEBUG: SatÄ±cÄ± adÄ± bulundu ({selector}): {result['seller_name']}")
                    break
            except:
                continue
        
        # SatÄ±cÄ± PuanÄ± - GeliÅŸmiÅŸ selector'lar
        seller_score_selectors = [
            '.seller-store__score.score-actual.ss-header-score',
            '.seller-store__score',
            '.score-actual',
            '.ss-header-score',
            'div[class*="seller-store__score"]',
            'div[style*="background:#049B24"]',
            'div[style*="background-color: rgb(4, 155, 36)"]',
            '.seller-score',
            '.merchant-score',
            '[data-testid="seller-score"]'
        ]
        
        for selector in seller_score_selectors:
            try:
                element = driver.find_element(By.CSS_SELECTOR, selector)
                if element:
                    score_text = element.text.strip()
                    print(f"ğŸ” SELLER DEBUG: SatÄ±cÄ± puanÄ± element text ({selector}): '{score_text}'")
                    
                    score_match = re.search(r'(\d+[,.]?\d*)', score_text)
                    if score_match:
                        result['seller_score'] = float(score_match.group(1).replace(',', '.'))
                        print(f"âœ… SELLER DEBUG: SatÄ±cÄ± puanÄ± bulundu ({selector}): {result['seller_score']}")
                        break
            except:
                continue
        
        # ÃœrÃ¼n SayÄ±sÄ± - Sayfa iÃ§eriÄŸinde arama
        try:
            page_source = driver.page_source
            
            product_patterns = [
                r'(\d+(?:[.,]\d+)*)\s*[ÃœÃ¼]r[Ã¼u]n',
                r'(\d+(?:[.,]\d+)*)\s*adet\s*[Ã¼u]r[Ã¼u]n',
                r'(\d+(?:[.,]\d+)*)\s*product',
                r'Toplam\s*(\d+(?:[.,]\d+)*)',
                r'(\d+(?:[.,]\d+)*)\s*sonuÃ§',
                r'(\d+(?:[.,]\d+)*)\s*Ã¼rÃ¼n\s*bulundu',
                r'(\d+(?:[.,]\d+)*)\s*results?'
            ]
            
            for pattern in product_patterns:
                match = re.search(pattern, page_source, re.IGNORECASE)
                if match:
                    try:
                        product_count_str = match.group(1).replace(',', '').replace('.', '')
                        result['product_count'] = int(product_count_str)
                        print(f"âœ… SELLER DEBUG: ÃœrÃ¼n sayÄ±sÄ± bulundu (pattern {pattern}): {result['product_count']}")
                        break
                    except ValueError:
                        continue
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: ÃœrÃ¼n sayÄ±sÄ± arama hatasÄ±: {str(e)}")
        
        # TakipÃ§i SayÄ±sÄ± - Sayfa iÃ§eriÄŸinde arama - TÃœRKÄ°YE FORMATI (VIRGÃœL)
        try:
            page_source = driver.page_source
            
            follower_patterns = [
                # YENÄ°: DOÄRU SIRALAMA - SayÄ± TakipÃ§i'den Ã–NCE
                r'(\d+[,.]?\d*[BMK]?)\s*[Tt]akip[Ã§c]i',        # "14,6B TakipÃ§i" 
                r'(\d+[,.]?\d*[BMK]?)\s*follower',             # "14,6B follower"
                r'(\d+[,.]?\d*[BMK]?)\s*ki[ÅŸs]i\s*takip',      # "14,6B kiÅŸi takip"
                r'(\d+[,.]?\d*[BMK]?)\s*followers?',           # "14,6B followers"
                
                # HTML'den Ã§Ä±karÄ±lan spesifik pattern
                r'>(\d+,\d+B)</span>\s*Takip[Ã§c]i',           # ">14,6B</span> TakipÃ§i"
                r'font-weight[^>]*>(\d+,\d+B)</span>',        # "font-weight: 600;">14,6B</span>"
                
                # BoÅŸluklu formatlar
                r'(\d+[,.]?\d*)\s*[BMK]\s*[Tt]akip[Ã§c]i',     # "14,6 B TakipÃ§i" 
                r'(\d+[,.]?\d*)\s*[BMK]\s*follower',          # "14,6 B follower"
                
                # Eski formatlar (TERS - TakipÃ§i Ã¶nce)
                r'[Tt]akip[Ã§c]i[^0-9]*(\d+[,.]?\d*[BMK]?)',   # ESKÄ°: "TakipÃ§i: 14,6B" 
                
                # TÃ¼rkiye spesifik formatlarÄ±
                r'(\d+,\d+B)\s*[Tt]akip[Ã§c]i',               # "14,6B TakipÃ§i"
                r'(\d+,\d+K)\s*[Tt]akip[Ã§c]i',               # "1,2K TakipÃ§i"
                r'(\d+,\d+M)\s*[Tt]akip[Ã§c]i'                # "1,5M TakipÃ§i"
            ]
            
            print(f"ğŸ” SELLER DEBUG: TakipÃ§i aramaya baÅŸlÄ±yor - sayfa uzunluÄŸu: {len(page_source)}")
            
            # Debug: "14,6" veya "takipÃ§i" iÃ§eren kÄ±sÄ±mlarÄ± bul
            debug_lines = []
            for line in page_source.split('\n'):
                line_clean = line.strip()
                if ('takip' in line_clean.lower() and any(char.isdigit() for char in line_clean)) or '14,6' in line_clean:
                    debug_lines.append(line_clean)
            
            print(f"ğŸ” SELLER DEBUG: TakipÃ§i ile ilgili {len(debug_lines)} satÄ±r bulundu")
            for i, line in enumerate(debug_lines[:5]):  # Ä°lk 5 tanesini gÃ¶ster
                print(f"  {i+1}. {line[:150]}...")
            
            # Ã–zel olarak "14,6B" ara
            if "14,6B" in page_source:
                print(f"âœ… SELLER DEBUG: '14,6B' metni sayfada bulundu!")
                # 14,6B Ã§evresindeki metni bul
                index = page_source.find("14,6B")
                surrounding = page_source[max(0, index-50):index+100]
                print(f"ğŸ” SELLER DEBUG: '14,6B' Ã§evresi: '{surrounding}'")
            else:
                print(f"âŒ SELLER DEBUG: '14,6B' metni sayfada bulunamadÄ±")
                # Alternatif formatlarÄ± ara
                if "14.6B" in page_source:
                    print(f"âœ… SELLER DEBUG: '14.6B' (noktalÄ±) bulundu")
                if "14,6" in page_source:
                    print(f"âœ… SELLER DEBUG: '14,6' (virgÃ¼llÃ¼ sayÄ±) bulundu")
                if "14.6" in page_source:
                    print(f"âœ… SELLER DEBUG: '14.6' (noktalÄ± sayÄ±) bulundu")
            
            for pattern in follower_patterns:
                matches = re.findall(pattern, page_source, re.IGNORECASE)
                if matches:
                    print(f"ğŸ” SELLER DEBUG: Pattern '{pattern}' ile bulunan matches: {matches}")
                    for match in matches:
                        try:
                            follower_text = str(match)
                            parsed_count = parse_follower_count(follower_text)
                            if parsed_count > 0:
                                result['follower_count'] = parsed_count
                                print(f"âœ… SELLER DEBUG: TakipÃ§i sayÄ±sÄ± bulundu (pattern {pattern}): {follower_text} -> {parsed_count}")
                                break
                        except Exception as e:
                            print(f"âš ï¸ SELLER DEBUG: Parse hatasÄ±: {follower_text} - {str(e)}")
                            continue
                if result.get('follower_count'):
                    break
                    
            if not result.get('follower_count'):
                print(f"âŒ SELLER DEBUG: HiÃ§bir takipÃ§i pattern'i Ã§alÄ±ÅŸmadÄ±")
                
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: TakipÃ§i sayÄ±sÄ± arama hatasÄ±: {str(e)}")
        
        print(f"ğŸ“Š SELLER DEBUG: TÃ¼m Ã¼rÃ¼nler sayfasÄ± sonucu: {result}")
        return result
        
    except Exception as e:
        print(f"âŒ SELLER DEBUG: TÃ¼m Ã¼rÃ¼nler scraping hatasÄ±: {str(e)}")
        logging.error(f"TÃ¼m Ã¼rÃ¼nler scraping hatasÄ± - {url}: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_seller_profile_page_selenium(url: str) -> Optional[Dict[str, any]]:
    """
    Selenium ile SatÄ±cÄ± Profil SayfasÄ±'ndan veri Ã§eker
    Returns: {'store_age': int, 'location': str, 'total_reviews': int, 'total_comments': int, 'overall_rating': float}
    """
    # Ã–nce Chrome driver dene
    try:
        driver = setup_chrome_driver()
    except Exception as e:
        print(f"âŒ SELLER DEBUG: Selenium baÅŸarÄ±sÄ±z, profil scraping atlanÄ±yor")
        return {
            'store_age': None,
            'location': None,
            'total_reviews': None,
            'total_comments': None,
            'overall_rating': None
        }
    
    try:
        print(f"ğŸ” SELLER DEBUG: SatÄ±cÄ± profil sayfasÄ± Ã§ekiliyor: {url}")
        driver.get(url)
        
        # Sayfa yÃ¼klenene kadar bekle
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScript'in tam yÃ¼klenmesi iÃ§in bekleme
        time.sleep(random.uniform(3, 6))
        
        # SayfayÄ± scroll et
        driver.execute_script("window.scrollTo(0, 800);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        result = {
            'store_age': None,
            'location': None,
            'total_reviews': None,
            'total_comments': None,
            'overall_rating': None
        }
        
        # Bot tespit kontrolÃ¼
        page_title = driver.title
        if "robot" in page_title.lower() or "captcha" in page_title.lower():
            print("ğŸ¤– SELLER DEBUG: Bot tespit sayfasÄ± algÄ±landÄ±!")
            return None
        
        print(f"ğŸ” SELLER DEBUG: Profil sayfasÄ± baÅŸlÄ±ÄŸÄ±: {page_title}")
        
        page_source = driver.page_source
        
        # MaÄŸaza YaÅŸÄ± - Pattern matching
        try:
            age_patterns = [
                r'(\d+)\s*[Yy][Ä±i]l',
                r'(\d+)\s*year',
                r'Ma[ÄŸg]aza\s*ya[ÅŸs][Ä±i][^0-9]*(\d+)',
                r'[Aa]Ã§[Ä±i]l[Ä±i][ÅŸs]\s*tarihi[^0-9]*(\d+)',
                r'(\d+)\s*yÄ±ldÄ±r',
                r'(\d+)\s*senedir'
            ]
            
            for pattern in age_patterns:
                match = re.search(pattern, page_source, re.IGNORECASE)
                if match:
                    try:
                        result['store_age'] = int(match.group(1))
                        print(f"âœ… SELLER DEBUG: MaÄŸaza yaÅŸÄ± bulundu (pattern {pattern}): {result['store_age']}")
                        break
                    except ValueError:
                        continue
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: MaÄŸaza yaÅŸÄ± arama hatasÄ±: {str(e)}")
        
        # Konum - GeliÅŸtirilmiÅŸ ve spesifik Ã§ekme
        try:
            # Ã–nce spesifik selector'larla dene
            location_selectors = [
                '.seller-info-container__wrapper__text-container__value',  # HTML'den Ã§Ä±kan class
                'span[class*="text-container__value"]',                     # Partial class
                '.seller-info-container span[class*="value"]'               # Container iÃ§inde value
            ]
            
            for selector in location_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    for i, element in enumerate(elements):
                        # Bir Ã¶nceki element'i kontrol et (title olabilir)
                        try:
                            parent = element.find_element(By.XPATH, "..")
                            title_element = parent.find_element(By.CSS_SELECTOR, '.seller-info-container__wrapper__text-container__title')
                            title_text = title_element.text.strip().lower()
                            
                            if 'konum' in title_text:
                                location_text = element.text.strip()
                                if location_text and len(location_text) < 50:  # Makul bir ÅŸehir adÄ± uzunluÄŸu
                                    result['location'] = location_text
                                    print(f"âœ… SELLER DEBUG: Konum bulundu (spesifik selector): {location_text}")
                                    break
                        except:
                            continue
                    
                    if result.get('location'):
                        break
                except:
                    continue
            
            # EÄŸer spesifik selector Ã§alÄ±ÅŸmazsa pattern matching dene
            if not result.get('location'):
                cities = [
                    'Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya', 'Adana', 'Konya', 'Gaziantep',
                    'Mersin', 'DiyarbakÄ±r', 'Kayseri', 'EskiÅŸehir', 'Urfa', 'Malatya', 'Erzurum',
                    'Van', 'Batman', 'ElazÄ±ÄŸ', 'Ä°Ã§el', 'Sivas', 'Manisa', 'Tarsus', 'KahramanmaraÅŸ',
                    'Erzincan', 'Ordu', 'BalÄ±kesir', 'KÄ±rÄ±kkale', 'KÃ¼tahya', 'TekirdaÄŸ', 'Afyon',
                    'Zonguldak', 'Ã‡orum', 'Denizli', 'Isparta', 'Samsun', 'Trabzon', 'Sakarya',
                    'Kocaeli', 'Hatay', 'Mardin', 'ÅanlÄ±urfa', 'AdÄ±yaman', 'MuÄŸla', 'Aksaray'
                ]
                
                # "Konum" kelimesinden sonra ÅŸehir ara
                location_patterns = [
                    r'[Kk]onum[^a-zA-ZÄ±ÄŸÃ¼ÅŸÃ¶Ã§Ä°ÄÃœÅÃ–Ã‡]*([a-zA-ZÄ±ÄŸÃ¼ÅŸÃ¶Ã§Ä°ÄÃœÅÃ–Ã‡\s]+)',
                    r'>Konum</span><span[^>]*>([^<]+)<',  # HTML tag pattern
                    r'title">Konum</span><span[^>]*>([^<]+)<'
                ]
                
                for pattern in location_patterns:
                    match = re.search(pattern, page_source, re.IGNORECASE)
                    if match:
                        location_text = match.group(1).strip()
                        for city in cities:
                            if city in location_text:
                                result['location'] = city
                                print(f"âœ… SELLER DEBUG: Konum bulundu (pattern matching): {city}")
                                break
                        if result.get('location'):
                            break
                            
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: Konum arama hatasÄ±: {str(e)}")
        
        # Genel Rating - Profil sayfasÄ±nda arama (HTML'den Ã§Ä±karÄ±lan)
        try:
            rating_selectors = [
                '.product-review-section-wrapper__wrapper__rating_wrapper_left__rating_value',  # HTML'den
                'span[class*="rating_value"]',  # Partial class
                'span[class*="rating_wrapper_left"]',  # Parent class
                '.product-review-section span[class*="rating"]',  # Section iÃ§inde
                '.rating-value',  # Genel selector
                '.overall-rating',  # Genel selector
                '[data-testid="rating"]',  # Test ID
                'div[class*="rating"] span',  # Div iÃ§inde span
                '.rating-score'  # Score class
            ]
            
            print(f"ğŸ” SELLER DEBUG: Rating aranÄ±yor - {len(rating_selectors)} selector denenecek")
            
            for selector in rating_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    print(f"ğŸ” SELLER DEBUG: Rating selector ({selector}) - {len(elements)} element bulundu")
                    
                    for element in elements:
                        rating_text = element.text.strip()
                        print(f"ğŸ” SELLER DEBUG: Rating element text ({selector}): '{rating_text}'")
                        
                        if rating_text:
                            # Rating deÄŸerini Ã§Ä±kar (4.2 gibi)
                            rating_match = re.search(r'(\d+[,.]?\d*)', rating_text)
                            if rating_match:
                                try:
                                    rating_value = float(rating_match.group(1).replace(',', '.'))
                                    if 0 <= rating_value <= 5:  # GeÃ§erli rating aralÄ±ÄŸÄ±
                                        result['overall_rating'] = rating_value
                                        print(f"âœ… SELLER DEBUG: Genel rating bulundu ({selector}): {result['overall_rating']}")
                                        break
                                except ValueError:
                                    continue
                    if result.get('overall_rating'):
                        break
                except Exception as e:
                    print(f"âš ï¸ SELLER DEBUG: Rating selector hatasÄ± ({selector}): {str(e)}")
                    continue
            
            # Pattern matching ile de dene
            if not result.get('overall_rating'):
                print(f"ğŸ” SELLER DEBUG: Selector'lar baÅŸarÄ±sÄ±z, pattern matching deneniyor")
                page_source = driver.page_source
                
                # "4.2" gibi sayÄ±larÄ± ara
                if "4.2" in page_source:
                    print(f"âœ… SELLER DEBUG: '4.2' metni sayfada bulundu!")
                    # 4.2 Ã§evresindeki metni bul
                    index = page_source.find("4.2")
                    surrounding = page_source[max(0, index-100):index+100]
                    print(f"ğŸ” SELLER DEBUG: '4.2' Ã§evresi: '{surrounding[:200]}'")
                else:
                    print(f"âŒ SELLER DEBUG: '4.2' metni sayfada bulunamadÄ±")
                
                rating_patterns = [
                    r'rating_value[^>]*>(\d+[,.]?\d*)',  # HTML class'Ä±ndan
                    r'[Gg]enel\s*[Rr]ating[^0-9]*(\d+[,.]?\d*)',
                    r'[Gg]enel\s*[Pp]uan[^0-9]*(\d+[,.]?\d*)',
                    r'[Oo]rtalama\s*[Pp]uan[^0-9]*(\d+[,.]?\d*)',
                    r'(\d+[,.]?\d*)\s*/\s*5',
                    r'[Rr]ating[^0-9]*(\d+[,.]?\d*)',
                    r'(\d+[,.]?\d*)\s*puan'
                ]
                
                for pattern in rating_patterns:
                    matches = re.findall(pattern, page_source, re.IGNORECASE)
                    if matches:
                        print(f"ğŸ” SELLER DEBUG: Rating pattern '{pattern}' ile bulunan matches: {matches}")
                        for match in matches:
                            try:
                                rating_text = str(match).replace(',', '.')
                                rating_value = float(rating_text)
                                if 0 <= rating_value <= 5:
                                    result['overall_rating'] = rating_value
                                    print(f"âœ… SELLER DEBUG: Genel rating bulundu (pattern {pattern}): {result['overall_rating']}")
                                    break
                            except ValueError:
                                continue
                        if result.get('overall_rating'):
                            break
                            
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: Genel rating arama hatasÄ±: {str(e)}")
     

                # Total Reviews ve Total Comments Ã§ekme
        try:
            reviews_selectors = [
                '.product-review-section__review-count.ta-right',  # HTML'den Ã§Ä±kan class
                'span[class*="review-count"]',                      # Partial class match
                '.product-review-section__review-count'             # Genel class
            ]
            
            for selector in reviews_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        print(f"ğŸ” SELLER DEBUG: Review element text ({selector}): '{text}'")
                        
                        # "664 DeÄŸerlendirme" formatÄ±nÄ± ara
                        if 'deÄŸerlendirme' in text.lower():
                            number_match = re.search(r'(\d+(?:[.,]\d+)*)', text)
                            if number_match:
                                result['total_reviews'] = int(number_match.group(1).replace(',', '').replace('.', ''))
                                print(f"âœ… SELLER DEBUG: Total reviews bulundu: {result['total_reviews']}")
                        
                        # "426 Yorum" formatÄ±nÄ± ara  
                        elif 'yorum' in text.lower() and 'yayÄ±nlama' not in text.lower():
                            number_match = re.search(r'(\d+(?:[.,]\d+)*)', text)
                            if number_match:
                                result['total_comments'] = int(number_match.group(1).replace(',', '').replace('.', ''))
                                print(f"âœ… SELLER DEBUG: Total comments bulundu: {result['total_comments']}")
                    
                    if result.get('total_reviews') and result.get('total_comments'):
                        break
                except Exception as e:
                    print(f"âš ï¸ SELLER DEBUG: Selector hatasÄ± ({selector}): {str(e)}")
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ SELLER DEBUG: Reviews/Comments arama hatasÄ±: {str(e)}")


        print(f"ğŸ“Š SELLER DEBUG: Profil sayfasÄ± sonucu: {result}")
        return result
        
    except Exception as e:
        print(f"âŒ SELLER DEBUG: Profil scraping hatasÄ±: {str(e)}")
        logging.error(f"Profil scraping hatasÄ± - {url}: {str(e)}")
        return None
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def scrape_single_seller(seller_link_id: int, all_products_url: str, seller_profile_url: str, scraped_by: str) -> bool:
    """
    Tek bir satÄ±cÄ± iÃ§in complete scraping yapar (Selenium ile)
    """
    try:
        print(f"ğŸ” SELLER DEBUG: SatÄ±cÄ± scraping baÅŸlatÄ±lÄ±yor: {seller_link_id}")
        
        # TÃ¼m Ã¼rÃ¼nler sayfasÄ±ndan veri Ã§ek
        all_products_data = scrape_all_products_page_selenium(all_products_url)
        if not all_products_data:
            print(f"âŒ SELLER DEBUG: TÃ¼m Ã¼rÃ¼nler sayfasÄ± veri Ã§ekme baÅŸarÄ±sÄ±z: {all_products_url}")
            return False
        
        # Ä°ki sayfa arasÄ± bekleme
        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
        
        # Profil sayfasÄ±ndan veri Ã§ek
        profile_data = scrape_seller_profile_page_selenium(seller_profile_url)
        if not profile_data:
            print(f"âš ï¸ SELLER DEBUG: Profil sayfasÄ± veri Ã§ekme baÅŸarÄ±sÄ±z, varsayÄ±lan deÄŸerlerle devam: {seller_profile_url}")
            profile_data = {
                'store_age': 0,
                'location': '',
                'total_reviews': 0,
                'total_comments': 0,
                'overall_rating': 0.0
            }
        
        # Verileri birleÅŸtir - VarsayÄ±lan deÄŸerler ekle
        combined_data = {
            'seller_name': all_products_data.get('seller_name', ''),
            'seller_score': all_products_data.get('seller_score', 0.0),
            'product_count': all_products_data.get('product_count', 0),
            'follower_count': all_products_data.get('follower_count', 0),
            'store_age': profile_data.get('store_age', 0),
            'location': profile_data.get('location', ''),
            'total_reviews': profile_data.get('total_reviews', 0),      # VarsayÄ±lan: 0
            'total_comments': profile_data.get('total_comments', 0),    # VarsayÄ±lan: 0
            'overall_rating': profile_data.get('overall_rating', 0.0)   # VarsayÄ±lan: 0.0
        }
        
        print(f"ğŸ“Š SELLER DEBUG: Kaydedilecek birleÅŸik veri: {combined_data}")
        
        # Veri kaydet
        success = save_seller_data(
            seller_link_id=seller_link_id,
            seller_name=combined_data['seller_name'],
            seller_score=combined_data['seller_score'],
            product_count=combined_data['product_count'],
            follower_count=combined_data['follower_count'],
            store_age=combined_data['store_age'],
            location=combined_data['location'],
            total_reviews=combined_data['total_reviews'],
            total_comments=combined_data['total_comments'],
            overall_rating=combined_data['overall_rating'],
            scraped_by=scraped_by
        )
        
        if success:
            print(f"âœ… SELLER DEBUG: SatÄ±cÄ± scraping baÅŸarÄ±lÄ±: {seller_link_id}")
            return True
        else:
            print(f"âŒ SELLER DEBUG: Veri kaydetme hatasÄ±: {seller_link_id}")
            return False
            
    except Exception as e:
        print(f"âŒ SELLER DEBUG: SatÄ±cÄ± scraping exception: {seller_link_id} - {str(e)}")
        return False

# Durum yÃ¶netimi fonksiyonlarÄ±
def update_seller_scraping_status(is_running: bool = None, progress: int = None, 
                                 total: int = None, current_item: str = None,
                                 started_by: str = None, error: str = None,
                                 success_count: int = None, failed_count: int = None):
    """Scraping durumunu gÃ¼nceller"""
    global seller_scraping_status
    
    with seller_scraping_lock:
        if is_running is not None:
            seller_scraping_status['is_running'] = is_running
            if is_running:
                seller_scraping_status['start_time'] = time.time()
                seller_scraping_status['errors'] = []
                seller_scraping_status['success_count'] = 0
                seller_scraping_status['failed_count'] = 0
            
        if progress is not None:
            seller_scraping_status['current_progress'] = progress
            
        if total is not None:
            seller_scraping_status['total_items'] = total
            
        if current_item is not None:
            seller_scraping_status['current_item'] = current_item
            
        if started_by is not None:
            seller_scraping_status['started_by'] = started_by
            
        if error is not None:
            seller_scraping_status['errors'].append(error)
            
        if success_count is not None:
            seller_scraping_status['success_count'] = success_count
            
        if failed_count is not None:
            seller_scraping_status['failed_count'] = failed_count

def get_seller_scraping_status() -> Dict:
    """Mevcut scraping durumunu dÃ¶ndÃ¼rÃ¼r"""
    with seller_scraping_lock:
        status = seller_scraping_status.copy()
        if status['start_time']:
            status['elapsed_time'] = time.time() - status['start_time']
        else:
            status['elapsed_time'] = 0
        return status

def start_single_seller_scraping(seller_link_id: int, all_products_url: str, seller_profile_url: str, scraped_by: str):
    """
    Tek satÄ±cÄ± iÃ§in arka planda scraping baÅŸlatÄ±r (yeni satÄ±cÄ± eklendiÄŸinde)
    """
    def scrape_worker():
        try:
            success = scrape_single_seller(seller_link_id, all_products_url, seller_profile_url, scraped_by)
            if success:
                logging.info(f"Tek satÄ±cÄ± scraping tamamlandÄ±: {all_products_url}")
            else:
                logging.error(f"Tek satÄ±cÄ± scraping baÅŸarÄ±sÄ±z: {all_products_url}")
        except Exception as e:
            logging.error(f"Tek satÄ±cÄ± scraping worker hatasÄ±: {str(e)}")
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scrape_worker)
    thread.daemon = True
    thread.start()

def start_manual_seller_update(username: str) -> bool:
    """
    Manuel gÃ¼ncelleme baÅŸlatÄ±r (Admin yetkisi gerekli)
    TÃ¼m aktif satÄ±cÄ±lar iÃ§in scraping yapar
    """
    def manual_update_worker():
        try:
            update_seller_scraping_status(is_running=True, started_by=username)
            
            # TÃ¼m aktif satÄ±cÄ±larÄ± al
            sellers = get_active_seller_links()
            total_sellers = len(sellers)
            
            update_seller_scraping_status(total=total_sellers, progress=0)
            
            logging.info(f"Manuel satÄ±cÄ± gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_sellers} satÄ±cÄ±")
            
            success_count = 0
            failed_count = 0
            
            for i, seller in enumerate(sellers):
                seller_id = seller['id']
                all_products_url = seller['all_products_url']
                seller_profile_url = seller['seller_profile_url']
                
                # Durumu gÃ¼ncelle
                update_seller_scraping_status(
                    progress=i + 1,
                    current_item=f"SatÄ±cÄ± {i+1}/{total_sellers}: {seller.get('seller_name', 'Bilinmeyen')}"
                )
                
                # Scraping yap
                success = scrape_single_seller(seller_id, all_products_url, seller_profile_url, username)
                
                if success:
                    success_count += 1
                    update_seller_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Scraping hatasÄ±: {all_products_url}"
                    update_seller_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Bekleme sÃ¼resi (Selenium iÃ§in daha uzun)
                time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
            
            logging.info(f"Manuel satÄ±cÄ± gÃ¼ncelleme tamamlandÄ±: {success_count}/{total_sellers} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            error_msg = f"Manuel satÄ±cÄ± gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_seller_scraping_status(error=error_msg)
        finally:
            update_seller_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if seller_scraping_status['is_running']:
        logging.warning("SatÄ±cÄ± scraping zaten devam ediyor, yeni iÅŸlem baÅŸlatÄ±lmadÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=manual_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def start_scheduled_seller_update(username: str = "seller_scheduler") -> bool:
    """
    ZamanlanmÄ±ÅŸ gÃ¼ncelleme baÅŸlatÄ±r
    """
    def scheduled_update_worker():
        try:
            update_seller_scraping_status(is_running=True, started_by=username)
            
            # TÃ¼m aktif satÄ±cÄ±larÄ± al
            sellers = get_active_seller_links()
            total_sellers = len(sellers)
            
            update_seller_scraping_status(total=total_sellers, progress=0)
            
            logging.info(f"Otomatik satÄ±cÄ± gÃ¼ncelleme baÅŸlatÄ±ldÄ±: {total_sellers} satÄ±cÄ±")
            
            success_count = 0
            failed_count = 0
            
            for i, seller in enumerate(sellers):
                seller_id = seller['id']
                all_products_url = seller['all_products_url']
                seller_profile_url = seller['seller_profile_url']
                
                # Durumu gÃ¼ncelle
                update_seller_scraping_status(
                    progress=i + 1,
                    current_item=f"Otomatik: SatÄ±cÄ± {i+1}/{total_sellers}"
                )
                
                # Scraping yap
                success = scrape_single_seller(seller_id, all_products_url, seller_profile_url, username)
                
                if success:
                    success_count += 1
                    update_seller_scraping_status(success_count=success_count)
                else:
                    failed_count += 1
                    error_msg = f"Otomatik scraping hatasÄ±: {all_products_url}"
                    update_seller_scraping_status(error=error_msg, failed_count=failed_count)
                
                # Otomatik gÃ¼ncellemede daha uzun bekleme (Selenium iÃ§in)
                time.sleep(random.uniform(REQUEST_DELAY_MIN + 5, REQUEST_DELAY_MAX + 10))
            
            logging.info(f"Otomatik satÄ±cÄ± gÃ¼ncelleme tamamlandÄ±: {success_count}/{total_sellers} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            error_msg = f"Otomatik satÄ±cÄ± gÃ¼ncelleme hatasÄ±: {str(e)}"
            logging.error(error_msg)
            update_seller_scraping_status(error=error_msg)
        finally:
            update_seller_scraping_status(is_running=False, current_item="")
    
    # EÄŸer baÅŸka bir scraping devam ediyorsa baÅŸlatma
    if seller_scraping_status['is_running']:
        logging.warning("SatÄ±cÄ± scraping zaten devam ediyor, otomatik iÅŸlem atlandÄ±")
        return False
    
    # Arka planda Ã§alÄ±ÅŸtÄ±r
    thread = threading.Thread(target=scheduled_update_worker)
    thread.daemon = True
    thread.start()
    
    return True

def is_seller_scraping_running() -> bool:
    """Scraping iÅŸleminin devam edip etmediÄŸini kontrol eder"""
    return seller_scraping_status['is_running']

def get_seller_scraping_statistics() -> Dict:
    """
    Scraping istatistiklerini getirir
    """
    try:
        seller_stats = get_seller_statistics()
        scraping_stats = get_seller_scraping_status()
        
        return {
            'seller_stats': seller_stats,
            'scraping_status': scraping_stats
        }
        
    except Exception as e:
        logging.error(f"SatÄ±cÄ± scraping istatistik hatasÄ±: {str(e)}")
        return {}

# Test fonksiyonu
def test_single_seller_scraping_selenium(all_products_url: str, seller_profile_url: str):
    """Ä°ki URL iÃ§in test scraping (Selenium ile)"""
    logging.info(f"Test satÄ±cÄ± scraping baÅŸlatÄ±lÄ±yor (Selenium):")
    logging.info(f"TÃ¼m Ã¼rÃ¼nler: {all_products_url}")
    logging.info(f"Profil: {seller_profile_url}")
    
    print("ğŸ§ª TEST: Selenium ile scraping test ediliyor...")
    
    all_products_data = scrape_all_products_page_selenium(all_products_url)
    print("ğŸ“Š TÃ¼m Ã¼rÃ¼nler verisi:", all_products_data)
    
    # Test iÃ§in sayfa arasÄ± bekleme
    time.sleep(random.uniform(5, 8))
    
    profile_data = scrape_seller_profile_page_selenium(seller_profile_url)
    print("ğŸ“Š Profil verisi:", profile_data)
    
    return all_products_data, profile_data

# Chrome driver durumunu kontrol etme fonksiyonu
def check_chrome_driver():
    """Chrome driver'Ä±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol eder"""
    try:
        driver = setup_chrome_driver()
        driver.get("https://www.google.com")
        time.sleep(2)
        title = driver.title
        driver.quit()
        
        print(f"âœ… SELLER DEBUG: Chrome driver test baÅŸarÄ±lÄ± - Title: {title}")
        return True
    except Exception as e:
        print(f"âŒ SELLER DEBUG: Chrome driver test baÅŸarÄ±sÄ±z: {str(e)}")
        return False

def scrape_all_sellers(specific_seller_id=None):
    """
    TÃ¼m aktif satÄ±cÄ±larÄ± scraping yapar
    specific_seller_id: Sadece belirli bir satÄ±cÄ± iÃ§in scraping yapmak iÃ§in
    """
    try:
        from seller_tracking import get_db_connection
        
        conn = get_db_connection()
        
        if specific_seller_id:
            # Sadece belirli satÄ±cÄ± iÃ§in
            cursor = conn.execute('''
                SELECT id, all_products_url, seller_profile_url 
                FROM seller_links 
                WHERE id = ? AND is_active = 1
            ''', (specific_seller_id,))
            print(f"ğŸ¯ Tek satÄ±cÄ± scraping: ID {specific_seller_id}")
        else:
            # TÃ¼m aktif satÄ±cÄ±lar iÃ§in
            cursor = conn.execute('''
                SELECT id, all_products_url, seller_profile_url 
                FROM seller_links 
                WHERE is_active = 1
            ''')
            print("ğŸ”„ TÃ¼m aktif satÄ±cÄ±lar iÃ§in scraping baÅŸlatÄ±lÄ±yor")
        
        sellers = cursor.fetchall()
        conn.close()
        
        if not sellers:
            print(f"âš ï¸ Scraping yapÄ±lacak satÄ±cÄ± bulunamadÄ±")
            return False
        
        print(f"ğŸ“Š {len(sellers)} satÄ±cÄ± iÃ§in scraping baÅŸlatÄ±lÄ±yor")
        
        success_count = 0
        failed_count = 0
        
        for seller in sellers:
            seller_id, all_products_url, seller_profile_url = seller
            
            try:
                print(f"ğŸ”„ Scraping baÅŸlatÄ±lÄ±yor: SatÄ±cÄ± ID {seller_id}")
                
                # Tek satÄ±cÄ± scraping fonksiyonunu kullan
                success = scrape_single_seller(
                    seller_link_id=seller_id,
                    all_products_url=all_products_url,
                    seller_profile_url=seller_profile_url,
                    scraped_by="scrape_all_sellers"
                )
                
                if success:
                    success_count += 1
                    print(f"âœ… SatÄ±cÄ± {seller_id} scraping baÅŸarÄ±lÄ±")
                else:
                    failed_count += 1
                    print(f"âŒ SatÄ±cÄ± {seller_id} scraping baÅŸarÄ±sÄ±z")
                
                # SatÄ±cÄ±lar arasÄ± bekleme (sadece birden fazla satÄ±cÄ± varsa)
                if len(sellers) > 1:
                    time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
                    
            except Exception as e:
                failed_count += 1
                print(f"âŒ SatÄ±cÄ± {seller_id} scraping exception: {str(e)}")
        
        print(f"ğŸ“Š Scraping tamamlandÄ±: {success_count} baÅŸarÄ±lÄ±, {failed_count} baÅŸarÄ±sÄ±z")
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ scrape_all_sellers genel hatasÄ±: {str(e)}")
        logging.error(f"scrape_all_sellers hatasÄ±: {str(e)}")
        return False

print("âœ… Selenium Seller scraper modÃ¼lÃ¼ yÃ¼klendi - Production/Local uyumlu Chrome WebDriver")